---
title: "The detection and accurate estimation of frequency attenuation effects in masked repetition priming: A large scale web browser-based study"
format:
  tandf-pdf:
    keep-tex: true
    include-in-header:
      text: |
        \usepackage{lscape}
        \newcommand{\blandscape}{\begin{landscape}}
        \newcommand{\elandscape}{\end{landscape}}  
  tandf-html: default
author:
  - name: Roberto Petrosino
    affiliations:
      - ref: NYUAD
    orcid: 0000-0002-8502-3070
    email: roberto.petrosino@nyu.edu
  - name: Diogo Almeida
    affiliations:
      - ref: NYUAD
    orcid: 0000-0003-4674-8092
    email: diogo@nyu.edu
affiliations:
  - id: NYUAD
    name: New York University Abu Dhabi
    department: Psychology Program, Division of Science
    address: New York University Abu Dhabi
    city: Abu Dhabi
    country: United Arab Emirates
    postal-code: 129188
abstract: |
  This study investigates the controversy surrounding the sensitivity of masked repetition priming to word frequency: while unmasked priming exhibits a frequency attenuation effect, wherein high frequency words yield smaller repetition effects, this phenomenon has been inconsistently reported in masked priming. We conducted two large online experiments with rigorously validated frequency databases to reconcile past discrepancies. The first experiment confirmed the viability of conducting masked priming experiments in web browser-based settings. The pre-registered second study, designed for high statistical power and precision, identified a 10-ms attenuation effect under masked priming. This result suggests that the repetition effect in masked priming is less qualitatively distinct from unmasked priming than previously assumed. This finding has implications for masked priming experimental design and theoretical consequences for models of priming. Crucially, models that predict either the presence or absence of frequency attenuation under masked conditions need to account for a small but reliable effect.
keywords: 
  - masked repetition priming
  - frequency attenuation effect
  - online browser-based experiment
  - power analysis
bibliography: references.bib  
editor: 
  markdown: 
    wrap: 72
editor_options: 
  chunk_output_type: console
---

# Introduction {#sec-intro}

```{r}
#| label: libraries and workspace
#| echo: false
#| warning: false
#| error: false
#| message: false
#| output: false

library(tidyverse)
library(knitr)
library(gt)
library(gtExtras)
library(zoo)

load('frequency-effects_data.RData')
```

The masked priming technique has been an invaluable tool in visual word recognition research. It has allowed researchers to study the conditions under which orthographic, phonological, morphological, and semantic information impact access to visual word forms while mitigating strategic effects and minimizing the influence of controlled processes [@Forster1998]. First introduced in its traditional form by @ForsterDavis1984 [see also @EvettHumphreys1981], this technique involves a forward mask (i.e., usually a string of hashes, #####), followed by a prime string presented for very short time ($SOA < 60$ ms),^[*SOA: Stimulus Onset Asynchrony*, i.e. the time between the start of one stimulus (in our case, the prime stimulus) and the start of another stimulus (the target stimulus). In the standard repetition priming design, no backward mask occurs between the prime and the target, and therefore SOA equals the duration of prime presentation.] and a target string presented immediately after. Because the prime presentation is so brief and masked by preceding and subsequent stimuli, most participants report not being aware that a prime string has been presented, and can at most report a screen flicker just before the target presentation [@ForsterEtal2003].

Among possible manipulations of prime-target relatedness, masked repetition priming (in which the same word is presented as both the prime and target within the same trial: e.g., *love-LOVE*) has been well studied, because its response seems to be qualitatively different from the unmasked counterpart ($SOA > 60 ms$): while high-frequency words benefit less from repetition than low-frequency words in the unmasked design [*frequency attenuation effect*, henceforth FAE\; @ScarboroughEtal1977], this does not seem to be the case when the prime is masked [@ForsterDavis1984; @ForsterEtal1987; @SeguiGrainger1990; @Sereno1991; @ForsterDavis1991; @RajaramNeely1992; @BodnerMasson1997; @ForsterEtal2003; @Nievas2010].

This asymmetry in sensitivity to lexical frequency between the masked and unmasked repetition priming responses has been important in distinguishing among different models of priming in visual word recognition. More specifically, _interactive activation models_ [@McClellandRumelhart1981; @GraingerJacobs1996; @ColtheartEtal2001] conceive of priming as a "head start" in processing due to the pre-activation of the target word due to the presentation of the prime. Thus, according to _interactive activation_ models, priming is ultimately caused by a single mechanism, making the qualitatively different profiles for repetition priming in masked and unmasked conditions a difficult empirical finding to explain.

Similarly, episodic models [e.g., @Jacoby1981; @Jacoby1983] posit a different single mechanism for priming effects: the activation/retrieval of the episodic memory trace of the encounter with the prime word. These models therefore encounter the same type of difficulty in accounting for qualitatively different patterns of repetition priming effects in masked and unmasked conditions. A similar type of model, called the _memory recruitment model_ makes very similar predictions to the episodic memory models, positing a non-lexical source for priming effects [@BodnerMasson1997; @MassonBodner2003; @Bodner2014]. Repetition priming effects under this view stem from the exploitation, strategically or automatically, of a memory resource created by the encounter with the prime word. The frequency attenuation effect, under episodic and memory recruitment models alike, is predicted on the basis that low frequency primes, being more distinctive stimuli, create a more potent and effective memory resource compared to high frequency primes.

In contrast, other models appear to successfuly sidestep the problem posed by the qualitatively different repetition priming profiles observed in masked and unmasked conditions. One such model is the _entry-opening model_ [also known as the _bin model_\; @ForsterDavis1984]. According to this model, when the visual stimulus is presented, lexical entries are assigned to specific bins based on orthographic similarity. In the first stage (fast search stage), a fast, frequency-ordered search goes through the entries within a given bin, and compares each one with the the input stimulus, assigning to each entry a goodness-of-fit score. This comparison is fast and crude, and sorts entries into (a) perfect (i.e., no difference is detected between the input and the entry), (b) close (i.e., small differences are detected), and (c) irrelevant matches (i.e., substantial difference are detected). Any entry of type (a) or (b) is opened, so that the entry can be further analyzed and compared to the input in the subsequent verification stage. Under a masked presentation, the entry of the prime word is opened at the fast search stage, but the short duration of the stimulus prevents it from reaching the evaluation stage. Crucially, the entry is nonetheless left open. Upon the presentation of the target stimulus, the access procedure will follow its two stage course, with a frequency-sensitive fast search and a subsequent entry opening for evaluation/verification. In this view, the fast search for the target word proceeds normally, but the evaluation/verification procedure starts and ends sooner than it otherwise would, because the target entry has already been left open after the brief processing of the prime. Thus, the _entry-opening model_ explains the masked repetition priming as the benefit from having the entry of the target word already open by the time the second stage of recognition starts. Crucially, this occurs *after* the target word is initially accessed, which happens in order of frequency. Put differently, according to the _entry-opening model_, masked repetition priming occurs because of the time savings from not having to open the entry, which is a frequency-insensitive process (i.e., every entry takes the same time to be opened), but *after* the frequency-sensitive first access stage. As a consequence, the _entry-opening model_ predicts a frequency-insensitive masked repetition priming effect, which is what has been traditionally reported in the literature (see @tbl-litReview). In addition, it also (correctly) predicts that pseudowords should not benefit from masked repetition priming, as they have no entries in the mental lexicon to be left open after the brief processing of the prime.

```{.content-hidden}
NOTE: DECIDED TO REMOVE DISCUSSION OF BAYESIAN READER. This is basically because the predictions of this model are really unclear for the FAE. On the one hand, the model claims that masked priming occurs because the prime and target are treated as the same event, which predicts simply a frequency effect, but no interaction with repetition. However, Norris & Kinoshita (2008) do report the FAE, and it seems that their simulations of the model do predict a small FAE. However, they never explain this, or make this prediction explicit. They only say that they replicated the results from Kinoshita 2006 and leave it at that. In their 2018 EEG paper, they do not obtain an FAE behaviorally, but they seem indifferent to it. In none of the papers from Bayesian reader it seems that the FAE is actually discussed. The closest we get is in one paper I need to remember where they claim that a mix of high and low frequency words will create underestimates for the priors of frequent words and overestimates for priors of low frequency words. We can always add all these caveats if a reviewer wants it.
##-----
Finally, a more recent model called the Bayesian Reader (CITATION: Norris, 2006) conceives of visual word perception as a Bayesian inference problem, and is thus highly sensitive to task demands, as different tasks generate different perceptual hypotheses to be tested. When it comes to the frequency attenuation effect in masked priming, the predictions of the model are a little unclear. On the one hand, the Bayesian Reader model posits that under masked priming, the perceptual system is "tricked" into treating the prime and target presentations as a single event.  
```

```{.content-hidden}
is not easy to explain, as it seems to hint at two different mechanisms that are activated accordingly. In persisting activation models [@McClellandRumelhart1981; @GraingerJacobs1996; @ColtheartEtal2001], priming is seen as the "head start" effect that the prior presentation of the prime gives to the activation of the target. Therefore, regardless of the prime-target SOA, the priming magnitude is expected to be either inversely proportional to word frequency, especially if word frequency is encoded in terms of changes in connection strengths (or activation thresholds). In memory recruitment models [a.o., @BodnerMasson1997; @MassonBodner2003], priming is seen as the effect whereby the prior recruitment of the memory representation of the prime assist with the identification of the memory representation of the target. Similar to persistent activation models, memory recruitment models predict that, whatever the SOA is, the priming magnitude and word frequency inversely interact, since word frequency is encoded as episodic distinctiveness. As the episodic representations of low-frequency words are more distinctive (because they are by definition less heard and used), they would trigger a greater response than the high-frequency words. In contrast, in 
```

However, as @tbl-litReview shows, there are nonetheless a few studies that do report significant FAEs in masked repetition priming [@BodnerMasson2001; @Kinoshita2006; @NorrisKinoshita2008, @Nievas2010]. @BodnerMasson2001 report that when stimuli are presented in alternating case (e.g., _pHoNe_), this increases the lexical decision difficulty and therefore generates an extra incentive to draw on the memory resource created by the brief processing of the prime. Under such conditions, they were able to observe a statistically significant FAE. In the same vein, @Kinoshita2006 noticed that in earlier studies the low frequency words often had very high error rates, and suggested that perhaps many participants did not know them. If participants treated a substantial number of low frequency words as nonwords, and nonwords do not exhibit repetition priming under masked conditions, it could artificially depress the repetition priming effect for the low frequency condition alone, which could make any existing FAE harder to detect. In two separate experiments, @Kinoshita2006 showed that larger repetition priming effects for low frequency words were only obtained when the low frequency words were vetted to make sure the participants knew them prior to the experiment. Following up on @Kinoshita2006, @NorrisKinoshita2008 were also able to find an interaction between lexical frequency and repetition in masked repetition priming.

Finally, as @tbl-litReview shows, it is noteworthy that 15 out of 18 previous studies showed numerically larger masked priming effects for low frequency words as opposed to high frequency words, irrespective of statistical significance. Similarly, the average repetition effect for low frequency words in the studies reviewed in @tbl-litReview is 13 ms larger when compared to that of high frequency words. These results are not in line with the predictions dictated by the _entry opening model_, and seem to align better with the predictions made by _interactive activation models_ and _memory recruitment_ models.

\blandscape
```{r}
#| echo: false
#| warning: false
#| error: false
#| label: tbl-litReview
#| tbl-cap: "Summary of the masked repetition priming effects as a function of word frequency reported in the literature. The power range estimates were calculated by simulating 10,000 datasets with the corresponding sample size (N) and FAE = 15 ms and 30 ms."

lit_effects %>%
  left_join(., power_estimates_15, by=join_by("N" == "nsubj"), multiple="first") %>%
  left_join(., power_estimates_30, by=join_by("N" == "nsubj"), multiple="first", suffix = c("_15", "_30")) %>%
  mutate(across(MOP_HF:MOP_Interaction, as.numeric)) %>%
  #group_by(N) %>%
  gt(rowname_col = "PAPER") %>%
  #tab_options(row.striping.include_table_body = FALSE) %>% 
  tab_stubhead(label = "Study") %>%
  tab_spanner(
    label = "MOP (ms)", columns = c(MOP_HF, MOP_LF)
  ) %>% 
  tab_spanner(
    label = "FAE (ms)", columns = c(MOP_Interaction, `p<.05?`)
  ) %>%
  tab_spanner(
    label = "Power range [min max]", columns = c(`Power range_15`, `Power range_30`)
  ) %>%
  cols_label( LANGUAGE = "Language", 
              PRIME_DURATION = "SOA",
              MOP_HF = "HF", 
              MOP_LF = "LF", 
              MOP_Interaction = "ES",
              `p<.05?` = md("_p_<.05?"),
              `Power range_15` = "FAE=15ms",
              `Power range_30` = "FAE=30ms"
  ) %>%
  tab_footnote( 
    footnote = "SOA for each subject determined by pre-test", 
    locations = cells_body(column = "PRIME_DURATION", rows = 14)
  ) %>%
  tab_footnote(
    footnote = "Reported in Masson & Bodner (2003)",
    locations = cells_stub(rows = 16) 
  ) %>% 
  grand_summary_rows(
    columns = c(MOP_HF, MOP_LF, MOP_Interaction),
    fns = list(Mean ~ round(mean(.)),
               SD ~ round(sd(.))), 
    missing_text = " " 
  ) %>%
  grand_summary_rows(
    columns = c(MOP_Interaction),
    fns = list(Correlation ~ round(cor(MOP_HF, MOP_LF), 2)), 
    missing_text = " " 
  ) %>%
   sub_missing(
    missing_text = " "
  )
```
\elandscape

# The present study {#sec-study}

It is somewhat surprising that the status of the FAE in masked priming remains largely unresolved in the literature, given its non-negligible magnitude and its theoretical significance in elucidating the underlying cognitive processes of masked priming.

One possible interpretation of the conflicting past findings revolves around the fact that only 4 out of 18 studies demonstrate a statistically significant FAE in masked repetition priming. Notably, this number potentially diminishes further when considering that, among these four studies, the FAE is detected only through the pooling of data across multiple studies employing a unique alternating-case stimulus presentation [@BodnerMasson2001; @MassonBodner2003]. This line of reasoning suggests a qualitatively distinct profile between masked and unmasked repetition priming, with the FAE more firmly established in the latter.

Conversely, one could argue that 15 out of 18 studies exhibit numerically larger repetition effect sizes for low-frequency words compared to high-frequency words —- a pattern that is challenging to reconcile with a genuine absence of interaction between frequency and masked repetition. Additionally, the average FAE across all studies stands at 13 ms, a modest yet non-negligible effect size. In fact, the naïve assumption that the two conditions are similar enough across experiments could justify the use of a *t*-test with statistically significant results: *M_FAE* = 13, CI_95% = [7, 20]), *t*(17) = 4.24, $p=.0005$. These considerations suggest that a genuine FAE may exist in masked priming but might be smaller than the thresholds detectable by most previous experiments. This interpretation is supported by the results from @Adelman2014 in a large scale, multi-site lab-based study on orthographic priming. They report a small but reliable FAE, but only when the frequency counts of @BrysbaertNew2009 are used, and caution that this effect could simply be an orthographic neighborhood effect masquerading as a frequency effect, due to the high correlations between the two variables. 

Compounding this complexity, another potential contributor to past discrepancies is the reliance on the dated Kucera and Francis (1967) word frequency database, which 15 out of 18 studies have depended on. This poses a potential problem, as this frequency database has consistently demonstrated inferior predictive performance, particularly with low-frequency words, compared to more contemporary databases [@Burgess1998; @Zevin2002; @Balota2004; @BrysbaertNew2009; @Yap2009; @Brysbaert2011; @Gimenes2016; @Herdaugdelen2017; @Brysbaert2018]. Both of these issues are addressed in the subsequent sections.

## Issues with frequency databases {#sec-study-freq}

Due to the well-documented concerns over the reliability of the @KuceraFrancis1967 frequency database for psycholinguistic experiments [@Burgess1998; @Zevin2002; @Balota2004; @BrysbaertNew2009; @Yap2009; @Brysbaert2011; @Gimenes2016; @Herdaugdelen2017; @Brysbaert2018], our studies exclusively sourced materials from the HAL [@LundBurgess1996] and SUBTLEX$_{US}$ [@BrysbaertNew2009] databases, which reflect more recent linguistic usage and offer better validation in behavioral experiments [e.g., @Balota2004; @BrysbaertNew2009; @Yap2009; @Brysbaert2011; @Gimenes2016; @Herdaugdelen2017]. While these databases outperform @KuceraFrancis1967 in predicting psycholinguistic task outcomes, it is important to note potential discrepancies in individual frequency counts, particularly in the low and mid-frequency ranges. This variation, attributable to the primary genre of their sources (USENET groups for HAL and movie subtitles for SUBTLEX$_{US}$),[^frequency-databases] may have minimal impact on megastudies with large word samples [e.g., @Balota2004; @BrysbaertNew2009; @Yap2009; @Brysbaert2011; @Gimenes2016; @Herdaugdelen2017]. However, corpus-specific frequency skew can become significant when dealing with smaller samples of words, as is the case in most masked priming studies (cf. @Adelman2014). @tbl-exFreqSkew illustrates the potential discrepancy in considering words as high or low frequency based on the different aforementioned databases.

[^frequency-databases]: A separate, though relevant issue which cannot be addressed here is to how to mitigate the discrepancies across the databases available, but see @Yap2009, and @Brysbaert2011 for proposals about combining the frequency counts from different corpora.\label{fn-databases}

```{r}
#| echo: false
#| warning: false
#| error: false
#| label: tbl-exFreqSkew
#| tbl-cap: "Example of frequency count imbalances (in occurrences per million) across the frequency norms of Kucera & Francis (KF), HAL and SUBTLEX~US~ for 4 to 6 letter words."

freqSkew %>% 
  gt() %>%
  cols_label(
    `SUBTLEX-US` = md("SUBTLEX~US~")
  ) %>%
  fmt_number(decimals = 0, drop_trailing_zeros = TRUE) %>%
  tab_row_group(
    label = md("_Skew in KF_"),
    rows = 1:5
  ) %>%
  tab_row_group(
    label = md("_Skew in HAL_"),
    rows = 6:10
  ) %>%
  tab_row_group(
    label = md("_Skew in SUBTLEX~US~_"),
    rows = 11:15
  ) %>%
  row_group_order(groups = c("_Skew in KF_", "_Skew in HAL_", "_Skew in SUBTLEX~US~_"))

```

## Issues with statistical power {#sec-study-power}

The inconsistency of past findings regarding the FAE in masked priming has been linked to a potential lack of statistical power in previous research [@BodnerMasson1997; @BodnerMasson2001; @MassonBodner2003; @Adelman2014]. This is a plausible concern, as interactions like the FAE often require larger sample sizes for statistical detection [@PotvinSchtuz2000; @BrysbaertStevens2018] compared to main effects. We outline below three ways in which neglecting statistical power might frustrate our understanding of FAE in masked repetition priming.

First, our literature review revealed crucial gaps in the reporting of relevant statistical information, which impedes the assessment of the statistical power attained by past experiments. The inconsistent reporting of each conditions' standard deviations (only 7 out of 18 studies) and the complete absence of reporting of the correlation structure between conditions complicates power assessments. Researchers are thus forced to explore a range of plausible values for standard deviations and correlation structures on their own.

@tbl-litReview details our attempt to conduct power simulations for two hypothesized frequency attenuation effect sizes: 15 ms (close to the averaged FAE of 13 ms) and 30 ms (close to the only three observed statistically significant FAE in English). Standard deviations (ranging between 60 ms and 180 ms, in 10 ms increments) and correlation between conditions (uniformly set to range between 0.6 and 0.9, with 0.1 unit increments) were simulated for each study's sample size, with 10,000 replications for each simulation. These range of values were derived from our literature review and previous in lab and online experiments [@Petrosino2020; @PetrosinoEtal2023]. For each simulated dataset, a paired _t_-test was performed comparing the repetition effect for high frequency words and low frequency words. This calculation is mathematically identical to the interaction term in a 2x2 factorial within-subjects design (the squared *t* value is equal to the *F* value for the interaction calculated in the 2x2 rmANOVA), but it is less computationally expensive to perform in large scale simulations. Power to detect this interaction was then calculated as the proportion of significant tests obtained across replications. All else being equal, standard deviations and correlations between conditions have opposite effects on statistical power: increases in standard deviations lead to less power, while increases in correlation between conditions lead to more power.

The results reported in @tbl-litReview reveal a wide range of possible statistical power attained by previous studies, depending solely on the combination of plausible standard deviation and correlation across conditions. For instance, the study with the smallest sample size [@ForsterEtal1987, $N=16$] had a 2% to 24% chance of detecting a 15 ms frequency attenuation effect and a 4% to 84% chance to detect a 30 ms effect. Similarly, the study with the largest sample size [@RajaramNeely1992, $N=48$] exhibited a range of 4% to 76% for a 15 ms frequency attenuation effect and 9% to 100% for a 30 ms effect. As a consequence of the limited reporting of relevant statistical information in past studies, it is nearly impossible to determine if any of them were adequately powered to detect the effect of interest.

A second concern arising from the ambiguity surrounding statistical power in the literature is the potential impact of a prevalence of low-powered experiments on the scientific record. An excess of such experiments increases the risk of observed statistically significant effects being spurious [@Button2013]. As highlighted in @tbl-litReview, only 4 out of 18 studies demonstrate a statistically significant FAE. The absence of clarity regarding the statistical power of previous research poses challenges in assessing the likelihood of these significant findings being spurious.

Finally, it is widely acknowledged that experiments with approximately 50% power are akin to a coin toss in their ability to detect a true effect [@Cohen1992]. A less-appreciated fact is that, in the presence of even lower power (<25%), statistically significant results can substantially overestimate the effect size -- a type-M error [@GelmanCarlin2014]. When power drops to levels below 10%, a statistically significant result may occur even when the observed effect goes in the opposite direction of the true effect -- a type-S error [@GelmanCarlin2014]. Our power simulations for within-subjects data revealed a similar relationship between statistical power, type-M, and type-S errors in line with the observations detailed by @GelmanCarlin2014 for the independent samples $t$-test. For instance, at 10% power (a possibility for virtually all previous studies, as indicated in @tbl-litReview), a statistically significant result could indicate an overestimation of the magnitude of the frequency attenuation effect by a factor between 2 and 5, with a 5% chance of incorrectly determining the direction of the effect.

{{< embed notebooks/intro_lit-review_power-analysis.qmd#fig-power >}}

The two studies reported here were designed to mitigate these two confounding issues: the overreliance on the @KuceraFrancis1967 frequency data as well as a potential lack of statistical power observed in previous research. As a large increase in statistical power requires a large sample size, Experiment 1 aimed to assess the suitability of using *Labvanced* [@Labvanced2017], an online platform for running web browser-based experiments, for running masked priming studies online.

# Experiment 1 {#sec-exp1}

As evident in @tbl-litReview, conducting a properly powered experiment for a FAE close to the averaged value calculated from previous studies will require sample sizes that would be impractical to pursue in standard university research settings, typically quiet lab rooms with limited research computers. In response to this challenge, our study was exclusively conducted online, leveraging the growing trend in online behavioral research facilitated by HTML5 capabilities and the availability of advanced web software such as *jsPsych* [@deLeeuw2014], *PsychoJS* (the JavaScript counterpart of *PsychoPy*, @PeirceEtal2019), *Gorilla* [@Anwyl2020], and *Labvanced* [@Labvanced2017].

Notably, three recent studies have already demonstrated the viability of conducting masked priming experiments online, employing different software tools: @Angele2023 with *PsychoJS*, @Cayado2023 with *Gorilla* and @PetrosinoEtal2023 with *Labvanced*. In this study, we opted for *Labvanced* [@Labvanced2017], given our previous successful experience with it [@PetrosinoEtal2023]. Similar to *Gorilla*, *Labvanced* eliminates local installation issues, ensuring cross-platform consistency and simplifying experimental design without necessitating proficiency in additional programming languages.

## Methods {#sec-exp1-methods}

###  Participants {#sec-exp1-methods-participants}

Three hundred participants (145 females; _mean age_ = 38; _sd_ = 12) were recruited on the Prolific online platform (<https://www.prolific.com>). Several criteria were selected to ensure recruitment of native speakers of U.S. English. Participants had to be born in the Unites States of America, speak English as their first and only language, and have no self-reported language-related disorder. We encouraged participants to avoid any sort of distraction throughout the experiment, and to close any program that may be running in the background. Because the experiment was run online, participants could not be monitored during data collection. Finally, to further reduce variability across participants' devices, we restricted the experiment to be run on Google Chrome only, which is the most used browser worldwide [@w3counterGlobalStats], and reportedly performs better than any other across operating systems [likely thanks to the _Blink_ engine\; see @LukacsGaspar2023].

### Design {#sec-exp1-methods-design}

The masked priming procedured relied on a lexical decision task (LDT), in which a 2 (Frequency: _high_ vs _low_) x 2 (prime type: _repetition_ vs _unrelated_) factorial design was used. Both factors were manipulated within-subjects. The dependent variables were lexical decision latency (in miliseconds) and error rate (in percentages).

### Materials {#sec-exp1-methods-materials}

Two hundred five-letter English words were selected from the English Lexicon Project [ELP\; @balota2007], in which 100 words were selected from an upper and a lower frequency range, respectively.[^low-freq] It was not possible to identify two frequency ranges that were well separated from one another for both the HAL [@LundBurgess1996] and the SUBTLEX$_{US}$ [@BrysbaertNew2009] frequency databases. As @tbl-words_exp1 shows, we managed to do this only for the former, whereas some overlap was present in the latter. This is expected given the different source of the two databases (see above, and fn. \ref{fn-databases}). The two word subsets corresponded to the two word frequency conditions being tested: the high-frequency, and low-frequency conditions. In each condition, fifty words were randomly chosen to be presented as targets and related primes (for the related prime type condition), and the remaining fifty were presented as unrelated primes (for the unrelated prime type condition).

[^low-freq]: The experiment also included an even lower frequency condition (range: [3.0 5.01]; mean: 4.39, SD: 0.50), thus summing up to six hundred trials being presented in the experiment. However, the average error rate for this condition was 44% and 33 (out of the 50) target words used in the same condition had a error rate higher than 30%. This suggested that they might have not known these words (see @Kinoshita2006). For this reason, this condition was completely removed from analysis.


```{r}
#| echo: false
#| warning: false
#| error: false
#| label: tbl-words_exp1
#| tbl-cap: "Experiment 1. Descriptive statistics of the word item used. For both frequency databases, the word frequencies were converted to per-million count to ensure cross-comparison."

words %>% 
  filter(freq.bin != 'low') %>%
  mutate(Freq_HAL.Pm = (Freq_HAL * (10^6) / (131*10^6))) %>% # CHECK IF THE TRANSFORM HERE IS CORRECT
  mutate(freq.bin = fct_recode(freq.bin, low = "mid")) %>% 
  dplyr::group_by(freq.bin) %>%
  dplyr::summarise(N = n(),
            minFreq= min(Freq_HAL.Pm, na.rm = T), maxFreq=max(Freq_HAL.Pm, na.rm = T),
            meanFreq = mean(Freq_HAL.Pm, na.rm = T), sdFreq = sd(Freq_HAL.Pm, na.rm = T),
            minSUBFreq= min(SUBTLWF, na.rm = T), maxSUBFreq=max(SUBTLWF, na.rm = T),
            meanSUBFreq = mean(SUBTLWF, na.rm = T), sdSUBFreq = sd(SUBTLWF, na.rm = T),
            #meanRT=mean(as.numeric(I_Mean_RT), na.rm = T), sdRT=sd(as.numeric(I_Mean_RT), na.rm = T),
            #meanLength = mean(Length, na.rm = T), sdLength=sd(Length, na.rm = T)
            ) %>% 
  mutate(
    across(-freq.bin, ~ if_else(.<1, round(., 2), round(.)))
  ) %>% 
  gt() %>%
  tab_spanner(
    label = md("**HAL**"), 
    columns = c(minFreq: sdFreq)
  ) %>%
  tab_spanner(
    label = md("**SUBTLEX~US~**"), 
    columns = c(minSUBFreq: sdSUBFreq)
  ) %>%
  cols_label(freq.bin = "frequency", 
             minFreq = "min", maxFreq = "max", meanFreq = "mean", sdFreq = "SD", 
             minSUBFreq = "min", maxSUBFreq = "max", meanSUBFreq = "mean", sdSUBFreq = "SD") %>%
  gt_add_divider(columns=c("maxFreq", "maxSUBFreq"), weight=px(1))
  
```

Two-hundred five-letter phonotactically legal nonwords were randomly selected from the ELP database as well. Half of them were randomly selected to be presented as targets; the other half was instead used as unrelated nonword primes.


### Procedure {#sec-exp1-methods-proc}

Each recruited participant was assigned one of two word lists, which differed only in the relatedness of the prime with respect to the target; otherwise, the two lists presented the same set of target words and nonwords (300 items in total). In one list, the three conditions (high-frequency, low-frequency word conditions, and the non-word condition) had 25 target items being preceded by themselves (the *related* condition) and the remaining 25 target items being preceded by one of the unrelated primes belonging to the same frequency bin (the *unrelated* condition). In the other list, these assignments were reversed. The order of stimulus presentation was randomized for each participant.

After being recruited in the _Prolific_ online platform, participants were asked to click on a link redirecting them to the Labvanced online service. During the experiment, they were asked to perform a lexical decision task by pressing either the 'J' (for word) or 'F' (for non-word) keys on their keyboard. Each trial consisted of three different stimuli appearing at the center of the screen: a series of hashes (#####) presented for 500 ms, followed by a prime word presented for 33 ms, and finally the target word; the target word disappeared from the screen as soon as a decision was made. The motivation for the choice of a very short prime duration (as compared to the literature, in which it is usually between 50 and 60 ms; see @tbl-litReview) is threefold. First, previous experiments on *Labvanced* [e.g., @PetrosinoEtal2023] showed that, due to the inherent difficulties in presenting stimuli for very short set durations in the browser, a longer set duration would increase the number of trials in which the prime duration would rise above the subliminal threshold (usually set at 60 ms) due to timing inaccuracies and missing screen refreshes, which could trigger the adoption of experiment-wide strategies in the task, and ultimately contaminate the masked priming response [@Zimmerman2012]. Second, @Angele2023, @Cayado2023 and @PetrosinoEtal2023 have demonstrated that a 33 ms priming duration is sufficient to elicit repetition priming effects in online experiments. Finally, setting such a short prime duration prevents virtually everyone from consciously perceiving the prime word [cf. @ForsterEtal2003, @Nievas2010], and thus presents a less contaminated estimate of early putatively automatic processes in word recognition.

Participants were given 5 breaks throughout the experiment. When the experiment was over, the participants were then redirected to Prolific in order to validate their submission. The median time to finish the experiment was 11 minutes. Each participant was paid with a standard rate of GBP 9/hour.

## Data analysis {#sec-exp1-analysis}

Analysis scripts and an abridged version of the data collected can be found on online (<https://osf.io/ej8dh>). We performed three different steps of analyses (in sequential order), with the goal of only keeping data that pass a set of stringent inclusion criteria (`r format(nrow(exp1_rawdata.sub), big.mark=",", scientific=F)` observations in total). After removing participants and items with high error rates, we inspected the durations of prime stimuli and removed those that did not fell within our desired range. Finally, we removed RT outliers.

### Step 1: subject and item performance {#sec-exp1-analysis-performance}

Item and subject error rates were calculated, with a cutoff of 30%. Only `r exp1_step1_item.err %>% filter(condition_rec=='low') %>% count() %>% pull()` low-frequency words (*`r exp1_step1_item.err %>% filter(condition_rec=='low') %>% mutate(target_rec=tolower(target_rec)) %>% pull(target_rec)`*), `r exp1_step1_item.err %>% filter(condition_rec=='non-word') %>% count() %>% pull()` non-words (*`r exp1_step1_item.err %>% filter(condition_rec=='non-words') %>% mutate(target_rec=tolower(target_rec)) %>% pull(target_rec)`*), and `r exp1_info$n_recruited - exp1_step1_subj_remain` participants were removed, with `r exp1_step1_subj_remain` participants remaining.

### Step 2: prime durations {#sec-exp1-analysis-primeTime}

During the experiment, the duration of presentation of the prime word was recorded for every trial. Both the mean (mean = `r round(exp1_summary.primeTime$meanPrimeTime, 2)` ms) and the median (median = `r median(exp1_rawdata.sub$primeTime)` ms)  of prime durations were slightly larger than the intended value (33 ms). This distribution suggests some imprecision in prime duration during the experiment. This was expected and likely due to the inherent difficulty with timing precision of visual presentations in web browsers and the great variation of computer hardware and internet connections used by the participants. Both of these issues may be impossible to control, at least at the current state of browser development. However, in masked priming, in which the duration of the prime is an essential part of the design, such fluctuations may indeed hinder proper elicitation of the priming response. As a way to counteract the influence that such fluctuations might have on the priming response, we only kept trials whose prime durations were within a pre-set range from the intended prime duration of 33 ms. Taking a standard 60-Hz monitor as reference, the lower and the upper bounds were set respectively at `r exp1_info$prime_dur_lb` ms (i.e., the intended prime duration minus half of a full refresh cycle: $33-8~ ms$; noting that @Angele2023 already showed that no repetition priming effects are obtained with a 16.7ms prime duration) and `r exp1_info$prime_dur_ub` ms (i.e., the commonly accepted upper threshold of subliminal processing), in an attempt to remove any trial that could have been consciously perceived by participants. Only `r round((exp1_primeTimeRangeSummary$n[1] + exp1_primeTimeRangeSummary$n[2])*100/nrow(exp1_rawdata.sub))`% of the trials were out of this duration range. We take this as evidence that *Labvanced* is able to consistently present stimuli at short durations. Prime duration fluctuations were however observed, and they were likely due to external factors outside of experimenter control (such as computer hardware, internet connection speed, and number of active operations in the background). The out-of-range trial removal was performed on the data after the error rate removal procedure. A total of `r exp1_step2_subj_remain` participants and `r format(exp1_step2_trials_remain, big.mark=",", scientific=F)` observations were included in the next steps of analysis.

### Step 3: RT distribution {#sec-exp1-analysis-RT}

Finally, individual trials were excluded if their RT was below 200 ms and 1800 ms. `r exp1_step2_trials_remain - exp1_step3_trials_remain` observations were excluded at this stage of analysis (i.e., `r 1 - round((exp1_step3_trials_remain/exp1_step2_trials_remain)*100, 2)`% of the dataset). After removing incorrect trials, to ensure more accurate estimates, we also made sure that each condition for each each participant contained at least half of the total number of trials presented (i.e., 12). A total of `r format(exp1_final_trials_remain, big.mark=",", scientific=F)` observations and `r exp1_final_subj_remain` subjects were included in the statistical analysis below.

## Results {#sec-exp1-results}

For each frequency bin, priming effects were calculated for each subject by subtracting the subject's mean RT to the related condition from the subject's mean RT to the unrelated condition. Unstandardized (in ms) and standardized effect sizes (i.e., Cohen's *d*) were then calculated for each condition. @tbl-exp1-statsResults below reports the descriptive and inferential statistics of the experiment. Both frequency conditions show statistically significant repetition priming effects (*MOP_HF* = 23, CI_95% = [19, 27], *t*(281) = 10.4, $p<.0001$; *MOP_LF* = 30, CI_95% = [24, 36], *t*(281) = 9.75, $p<.0001$). Non-word repetition priming effects were inhibitory and were marginally statistically significant (*MOP_* = -4, CI_95% = [-8, 0], *t*(281) = -1.91, $p=0.057$). Finally, the low-frequency repetition priming effect was 7-ms larger than that of the high-frequency words, but this FAE effect was only marginally statistically significant (*M_FAE* = 7, CI_95% = [-1, 15]), *t*(281) = 1.88, $p=0.06$). As for the error analysis, we found a significant priming effect in all conditions (high: *t*(281)=2.51, $p<.0001$; low: *t*(281)=6.39, $p<.0001$; non-word: *t*(281)=-2.24, $p<.0001$). 

\blandscape
```{r}
#| echo: false
#| message: false
#| error: false
#| warning: false
#| label: tbl-exp1-statsResults
#| tbl-cap: "Experiment 1. Summary of the word priming results. *Legend.* MOP: magnitude of priming."
#| tbl-pos: 'h'

exp1_summary.results %>%
  relocate(c("sd_unrelated", "mean.error_unrelated"), .before=gd.mean_related) %>%
  gt() %>%
  cols_label(
    CI = "95% CI",
    contains("mean") ~ "mean",
    contains("sd") ~ "SD", 
    contains("error") ~ "Error (%)"
  ) %>%
  tab_spanner(
    label = "unrelated RT",
    columns = c(2:4)
  ) %>%
  tab_spanner(
    label = "repetition RT",
    columns = c(5:7)
  ) %>%
  tab_spanner(
    label = 'priming effects',
    columns = c(9:12)
  ) %>%
  tab_spanner(
    label = md("_t_-test"),
    columns = c(13:15)
  ) %>%
  cols_label(
    sd = md("SD~p~")
  ) %>%
  cols_label(
    t = md("_t_"),
    p = md("_p_"),
  ) %>%
   sub_missing(
    missing_text = " "
  )
```
\elandscape 

## Discussion {#sec-exp1-discussion}

The primary objective of Experiment 1 was to evaluate whether web browser-based stimulus delivery programs such as *Labvanced* can yield data comparable in quality to traditional lab-based experiments. The results indicate that this is indeed possible, but careful inspection of prime durations is nonetheless necessary.

Robust repetition priming was observed in both frequency conditions. The non-word condition triggered a small inhibitory repetition effect, in line with the previous literature [_inter alia_ @ForsterDavis1984, experiment 1 and 2\; @Forster1999], but this was not statistically significant. Crucially, we observed a 7 ms FAE effect that was marginally statistically significant. As noted elsewhere [@PotvinSchtuz2000], the absence of a significant interaction effect may easily arise due to low statistical power. 

The 95% CI was between -1 ms and 15 ms. This interval suggests that the actual FAE is possibly a positive value that can be as large as 15 ms. This is in line with the results from previous literature, with the caveat that the majority of previous experiments used ~50 ms prime durations, while experiment 1 used a 33 ms prime duration. Prime durations have been suggested to be an upper bound on the size of the masked repetition priming effect [@Forster1998], and thus it is not clear how much the FAE should vary as a function of the prime duration.

To address the concerns about the lack of statistical power and the substantial imprecision in the estimated FAE size observed in experiment 1, experiment 2 was designed to have a sample size that ensures acceptable statistical power to detect the an interaction between priming and frequency, as well as a sample size that reduces the width of the resulting confidence interval compared to experiment 1.

# Experiment 2

The findings from Experiment 1, as well as those reported by @Angele2023, @Cayado2023 and @PetrosinoEtal2023, establish the feasibility of obtaining masked repetition priming in online experiments with a 33 ms prime duration. However, a crucial question remains: can we reliably detect the FAE in web browser-based settings? Experiment 2 directly addresses concerns about the potential statistical power limitations observed in Experiment 1 and much of the prior literature. Specifically targeting what we construe as the smallest theoretically interesting FAE (5ms), we recruited a larger sample size, as determined by a power analysis. We simulated 10,000 datasets for each of the combinations of two statistical parameters: standard deviation and the correlation between conditions. The latter were kept equal across conditions to simplify the simulations. Based on our own pilot studies and previous published work [@Petrosino2020; @PetrosinoEtal2023], the simulations involved standard deviations ranging from 80 to 120 ms (with 10 ms increments), while the correlation between conditions ranged from 0.7 to 0.9 (with 0.1 increments). The sample size varied between 200 and 3,000 participants (with 150 unit increments). Three different FAE sizes were simulated: 15 ms, 10 ms and 5 ms. The first effect size (15 ms) is about half of the ones observed in previous studies that statistically detected the FAE (~30 ms). The second effect size (10 ms) is close to the size of the average frequency attenuation effect found in the literature (13 ms). The last effect size (5 ms) is our lower-bound estimate of a theoretically interesting effect size. The code used for the power simulations, along with the simulated datasets are available online (<https://osf.io/r7d2q/>).

Our analysis identified a sample size of 1,250 participants as optimal, ensuring robust statistical power (> 80%) across various parameter combinations (@fig-power-1250), especially for raw FAEs equal to or exceeding 10 ms —- a value closely aligned with the average FAE calculated from previous studies (refer to @tbl-litReview). In light of the observed limitations in the temporal accuracy and precision of current online stimulus delivery programs (discussed in @sec-exp1-analysis-primeTime), which necessitated substantial subject and data exclusion in Experiment 1, we aimed for an intended sample size of 2,600. This decision was made to enhance the likelihood of obtaining a sample size of at least 1,250 participants after applying all the necessary exclusion criteria to the data. In addition, sample sizes exceeding 1,250 can only help increase the precision of the estimated effect size.


```{r}
#| label: fig-power-1250
#| fig-cap: "Power simulations with a sample size of 1,250, for all combinations of standard deviation (sd), pairwise correlation (cor), and interaction effect size. The red line identifies the threshold of 80% power."

power_pred_df.sub1250 |>
  ggplot(aes(y = power_unadjusted, x = ES)) + 
    geom_line() + 
    geom_point() +
    geom_hline(yintercept = 0.8, color = "red2") + 
    facet_grid(rho ~ std_dev) +
  scale_x_continuous(breaks=seq(5, 15, 5), limits=c(5, 15), labels=seq(5, 15, 5),
    sec.axis = sec_axis(~ . , name = "sd", breaks = NULL, labels = NULL)) +
  scale_y_continuous(breaks=seq(0, 1, 0.2), limits=c(0, 1), labels=seq(0, 1, .2),
    sec.axis = sec_axis(~ . , name = "cor", breaks = NULL, labels = NULL)) +
  theme_bw()+
    theme(#axis.line = element_line(colour = "black"),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(), 
      panel.border = element_blank(),
      legend.position="none"
      #panel.background = element_blank() 
     )+
  labs(title="N=1,250", y = "power (unadjusted)", x = "FAE size (ms)")

``` 

## Methods {#sec-exp2-methods}

### Preregistration {#sec-exp2-prereg}

We preregistered the results of the power analysis, the goals, the design and analysis plan for experiment 2 prior to data collection. The preregistration, detailing the experimental hypotheses, the desired sample size as well as the planned analyses is available online (<https://doi.org/10.17605/OSF.IO/3NFQP>).

### Participants {#sec-exp2-methods-participants}

Two thousand and six hundred participants (1445 females; _mean age_ = 42, _sd age_ = 14) were recruited on Prolific (<https://www.prolific.com>) with the same criteria specified for experiment 1 (@sec-exp1-methods-participants).

### Design {#sec-exp2-methods-design}

The experimental design was identical to experiment 1.

### Materials {#sec-exp2-methods-materials}

One-hundred and four five-letter words, half of low frequency (between 7 and 24 in the SUBTLEX$_{US}$ frequency per million) and half of high frequency (between 57 and 2,961 in the SUBTLEX$_{US}$ frequency per million) were sampled from ELP [@balota2007], but this time based on the SUBTLEX$_{US}$ frequency counts rather than HAL (which was used in experiment 1). @tbl-words_exp2 shows that although the SUBTLEX$_{US}$ frequency ranges of the two conditions were very far from one another (similarly to what was done in Experiment 1; @sec-exp1-methods-materials), they still show some overlap when HAL frequencies are used. As mentioned before, this seems to be a general problem when jointly considering different frequency databases for a smaller set of stimuli that need to be manipulated and controlled in different ways (see also fn. \ref{fn-databases} and @Adelman2014). From each condition, fifty words were randomly chosen to be presented as targets and related primes (the *related* condition), and the remaining fifty were presented as unrelated primes (the *unrelated* condition). All words used were monomorphemic nouns, adjectives, or verbs, thus excluding particles, prepositions, and derived or inflected forms.

```{r}
#| echo: false
#| warning: false
#| error: false
#| label: tbl-words_exp2
#| tbl-cap: "Experiment 2. Descriptive statistics of the word items used. For both frequency databases, the word frequencies were converted to per-million count to ensure cross-comparison."

words_exp2 %>%
  group_by(freq.bin) %>%
  mutate(Freq_HAL.Pm = (Freq_HAL * 10^6)/(131 * 10^6)) %>%
  summarise(N = n(),
            minFreq= min(Freq_HAL.Pm, na.rm = T), maxFreq=max(Freq_HAL.Pm, na.rm = T),
            meanFreq = mean(Freq_HAL.Pm, na.rm = T), sdFreq = sd(Freq_HAL.Pm, na.rm = T),
            minSUBFreq= min(SUBTLWF, na.rm = T), maxSUBFreq=max(SUBTLWF, na.rm = T),
            meanSUBFreq = mean(SUBTLWF, na.rm = T), sdSUBFreq = sd(SUBTLWF, na.rm = T),
            #meanRT=mean(as.numeric(I_Mean_RT), na.rm = T), sdRT=sd(as.numeric(I_Mean_RT), na.rm = T),
            #meanLength = mean(Length, na.rm = T), sdLength=sd(Length, na.rm = T)
            ) %>% 
  mutate_if(is.numeric, ~round(.)) %>% 
  mutate_if(needs_mutated, ~round(.)) %>%
  gt() %>%
  cols_label(
    freq.bin = "frequency", 
    minFreq = "min", maxFreq = "max", meanFreq = "mean", sdFreq = "SD", 
    minSUBFreq = "min", maxSUBFreq = "max", meanSUBFreq = "mean", sdSUBFreq = "SD") %>%
  tab_spanner(
    label=md("**HAL**"),
    columns=3:6
  ) %>%
  tab_spanner(
    label=md("**SUBTLEX~US~**"),
    columns=7:10
  )
```

One-hundred and four five-letter, phonotactically legal nonwords were randomly selected from the ELP database as well. Half of them were randomly selected to be presented as targets; the other half was instead used as unrelated nonword primes. None of the nonwords contained any existing English morpheme. Both the words and non-words used in the experiments are reported in the appendix below.

### Procedure {#sec-exp2-methods-proc}

Experiment 2 followed the same procedures as experiment 1 (see @sec-exp1-methods-proc). The median time to finish the experiment was 5 minutes.

## Data analysis {#sec-exp2-analysis}

Analysis scripts and an abridged version of the data collected can be found online (<https://osf.io/vn3r2>), and consisted of `r format(nrow(exp2_rawdata.sub), big.mark=",", scientific=F)` observations in total. We performed the same three steps of analysis described for experiment 1 (@sec-exp1-analysis).

### Step 1: subject and item performance {#sec-exp2-analysis-performance}

Item and subject error rates were calculated. The item error rate was never below above 14%, so no item was excluded from analysis. `r exp2_info$n_recruited - exp2_step1_subj_remain` subjects were removed because their error rate was above 30%. Thus, a total of `r format(nrow(exp2_data_step1), big.mark=",", scientific=F)` observations and `r format(exp2_step1_subj_remain, big.mark=',', scientific=F)` participants were included in further analyses.

### Step 2: prime durations {#sec-exp2-analysis-primeTime}

Prime fluctuations were dealt with in the same way as in experiment 1 (@sec-exp1-analysis-primeTime). The mean (mean = `r round(exp2_summary.primeTime$meanPrimeTime, 2)` ms, sd = `r round(exp2_summary.primeTime$sdPrimeTime, 2)`) and the median (median = `r median(exp2_rawdata.sub$primeTime)` ms)  prime durations were closer to the intended value (33 ms). The same prime duration cut-off set for experiment 1 (i.e., any trial whose prime duration was out of the 25-60ms range) removed `r round((exp2_primeTimeRangeSummary$n[1] + exp2_primeTimeRangeSummary$n[2])*100/nrow(exp2_rawdata.sub))` % of the trials. No participant was excluded, for a total of `r format(exp2_step2_trials_remain, big.mark=",", scientific=F)` observations.

### Step 3: RT distribution {#sec-exp2-analysis-RT}

After removing the incorrect responses, similarly to what we did for experiment 1 (@sec-exp1-analysis-RT), `r 100-round(exp2_step3_trials_remain*100/exp2_step2_trials_remain, 2)`% of the trials were excluded if the relative RT was below 200 ms and above 1800 ms. Finally, `r length(exp2_subj_filter_2)` subjects were removed because the number of trials within the same condition was less than 7 (i.e., about half of the total number of trials being presented within the same condition, i.e. 13). A total of `r format(exp2_final_trials_remain, big.mark=",", scientific=F)` observations and `r format(exp2_final_subj_remain, big.mark=",", scientific=F)` subjects were included in the statistical analysis below. 

## Results {#sec-exp2-results}

For each frequency condition, priming effects were calculated in the same way as experiment 1. @tbl-exp2-statsResults below report the descriptive statistics of the experiment. All three conditions showed statistically significant repetition priming effects (*MOP_HF* = 18, CI_95% = [16 20], t(2340) = 19.7, $p<.0001$; *MOP_LF* = 28, CI_95% = [26 30], *t*(2340) = 27.8, $p<.0001$; *MOP_NW* = -2, CI_95% = [-4 0], t(2340) = -2.33, $p<.0001$). The low-frequency word repetition priming effect was 10 ms larger than the high-frequency word repetition priming effect, and this FAE effect was statistically significant (*M_FAE* = 10, CI_95% = [7 13]), *t*(2340) = 7.24, $p<.0001$). As for the word error analysis, we found significant priming effects in the word conditions (high: *t*(2340)=9.95, *p*<.0001; low: *t*(2340)=16.9, *p*<.0001), as well as in the non-word condition (non-word: *t*(2340)=-3.27, *p*=.001). 

\blandscape
```{r}
#| echo: false
#| message: false
#| error: false
#| warning: false
#| label: tbl-exp2-statsResults
#| tbl-cap: "Experiment 2. Summary of the word priming results. *Legend.* MOP: magnitude of priming."
#| tbl-pos: 'h'

exp2_summary.results %>%
  relocate(c("sd_unrelated", "mean.error_unrelated"), .before=gd.mean_related) %>%
  gt() %>%
  cols_label(
    CI = "95% CI",
    contains("mean") ~ "mean",
    contains("sd") ~ "SD", 
    contains("error") ~ "Error (%)"
  ) %>%
  tab_spanner(
    label = "unrelated RT",
    columns = c(2:4)
  ) %>%
  tab_spanner(
    label = "repetition RT",
    columns = c(5:7)
  ) %>%
  tab_spanner(
    label = 'priming effects',
    columns = c(9:12)
  ) %>%
  tab_spanner(
    label = md("_t_-test"),
    columns = c(13:15)
  ) %>%
  cols_label(
    sd = md("SD~p~")
  ) %>%
  cols_label(
    t = md("_t_"),
    p = md("_p_"),
  ) %>%
   sub_missing(
    missing_text = " "
  )
```
\elandscape

## Discussion {#sec-exp2-discussion}

Experiment 2 was designed to investigate whether Frequency Attenuation Effects (FAE) can be detected under masked priming conditions (with SOA < 60 ms). We employed a robust sample size to ensure adequate statistical power for detecting small to medium effect sizes. Our results not only replicated Experiment 1 in revealing statistically significant main effects of repetition for high and low frequency words alike, but also detected a statistically significant interaction: the low-frequency condition yielded priming effects that were 10 ms larger than the high-frequency condition. This value is within the 95% CI from experiment 1, making it a successful replication of its result. The 95% CI of experiment 2 ranges from 7 ms to 13 ms. This is notable because it includes the effect size of experiment 1, and is quite narrow (a halfwidth of 3 ms). This indicates that, for the frequency ranges investigated in experiment 2, the FAE is unlikely to be smaller than 7 ms or larger than 13 ms when the prime duration is 33 ms. In contrast, experiment 1 had a halfwidth almost three times as large (8 ms).

The absence of a robust non-word masked priming response has been used as an additional piece of evidence supporting the view that the masked priming response is devoid of episodic influences [e.g., @Forster1999]. The results of experiment 2 align with the previous evidence (including that of experiment 1) in showing at best very small inhibitory masked repetition priming for non-words, with very high precision: the 95% CI indicates the plausible range for the masked repetition priming effect for non-words to be between -4 and 0 ms, at least when prime duration is 33 ms. 

# General discussion {#sec-discussion}

The repetition priming response stands as a cornerstone in psycholinguistic investigations, offering insights into the mechanisms governing word recognition. An ongoing debate surrounds the interpretation of these effects, particularly concerning their source in the memory system. On the one hand, _interactive activation models_ [@McClellandRumelhart1981; @GraingerJacobs1996; @ColtheartEtal2001] posit a lexical source for repetition priming effects, either in terms of temporarily raised resting activation levels for lexical nodes in unmasked priming, or as a head start in the retrieval process in masked priming. _Episodic_ and _memory recruitment models_ [@Jacoby1981; @Jacoby1983;  @BodnerMasson1997; @MassonBodner2003; @Bodner2014] on the other hand, invoke a non-lexical source for the repetition effect, namely an episodic or episodic-like memory resource formed upon brief exposure to the prime word that can be recruited during the processing of the target item. Crucially, both models predict a single mechanism underlying masked and unmasked priming. Differential mechanisms between unmasked and masked repetition priming, however, are predicted by the _entry-opening model_ [@ForsterDavis1984], which propose both lexical and episodic sources of priming effects.

Thus, the existence of qualitatively distinct outcomes in masked and unmasked priming presented a direct challenge to some, but not all of these models. One such finding is the *Frequency Attenuation Effect* (FAE), in which higher frequency words exhibit smaller repetition effects compared to lower frequency words. The FAE has been described as observable only in unmasked priming since the work of @ForsterDavis1984, who demonstrated that when the prime word is presented very briefly (SOA $<$ 60 ms), it becomes masked by the target word, and this is hypothesized to prevent the conscious encoding of the prime. Under such conditions, the FAE purportedly disappears. @ForsterDavis1984 argued that this potentially shows that the FAE is subserved by a different type of memory source (perhaps episodic) than the masked repetition priming response. This conclusion, however, is the source of ongoing debates (see @tbl-litReview for review of past findings), which the two experiments reported here were meant to address.

Within this research landscape, our experiments targeting the frequency sensitivity of the repetition effect under masked conditions contribute methodological and theoretical insights. Methodologically, our results help establish the viability and reliability of online data collection for the masked priming paradigm. Building on the work of @Angele2023, @Cayado2023 and @PetrosinoEtal2023, we addressed pitfalls in implementing and analyzing masked priming data collected online, and by doing so offered a solution to the longstanding problem of low statistical power and lack of estimation precision when it comes to investigating phenomena with effect sizes that are harder to detect statistically, like interactions in factorial designs. However, this newfound opportunity necessitates careful data scrutiny.

In the same vein, the FAEs observed in experiments 1 and 2 have important theoretical ramifications. The historical belief in the non-observability of FAE in masked priming primarily arose from a lack of statistically significant results, possibly rooted in outdated frequency corpora or inadequate statistical power. Our design addressed these concerns, yielding statistically significant FAE results aligning with the literature's average effect (see @tbl-litReview; the 95% CI implies that the FAE is unlikely to be larger than 13 ms with a 33 ms prime duration). These results challenge the supposed qualitative distinction between masked and unmasked repetition priming cleaved by the FAE, complicating the rejection of single-mechanism theories, and suggesting that _interactive-activation models_ and _memory recruitment models_ may yet offer unifying explanations for masked and unmasked priming.

Similarly, our results also challenge the entry-opening model's prediction of the absence of FAE in masked priming. One potential way of dealing with this in the _entry opening model_ is to claim that masked priming severely reduces, but does not entirely eliminate, the use of sources other than lexical memory [see @Forster1998; @ForsterEtal2003, for proposals along this line]. Alternatively, within the entry-opening model, the results of experiment 2 may be explained by the frequency-based mechanism occurring in the fast search stage. A potential mechanism in this direction was already hinted at by @ForsterDavis1984 themselves, and consists of a procedure, whereby during the fast search stage, the entry of a prime word is promoted to the top position of the search list. As a consequence, low-frequency words (which are fairly low in the search list) will benefit from such promotion procedure more than high-frequency words (which are instead already in higher positions), thus ultimately giving rise to the FAE.

While our findings present a compelling case for the presence of FAE in masked priming that is seemingly parallel to the unmasked case, questions about potential mechanistic differences persist. The larger sample size needed for masked FAEs raises intriguing considerations about the influence of memory sources and warrants further investigation. For example, there is independent evidence for different mechanisms in masked and unmasked repetition priming from RT distributional analyses (cf. @Gomez2013) that suggests that repetition priming under masked conditions affect primarily the encoding stage of the stimulus. Given that frequency is often associated with facilitation of encoding, our results could help support this view. Additionally, the trivially small effect sizes of non-word masked repetition priming in experiments 1 and 2 align with the trend (overwhelmingly shown in the literature) that this effect may be exclusive to unmasked designs [@Forster1998; @ForsterEtal2003; but see @MassonBodner2003], and suggests avenues for future exploration on large-scale.

Finally, the finding that the FAE occurs under masked priming conditions may impact our understanding of masked morphological priming. In this literature, there is a unresolved question about the ability of affixes to elicit masked morphological priming results [for a review, @AmentaCrepaldi2012]. In English, the evidence seems to indicate that only stems, but not affixes, have the ability to prime entries across the lexicon. This finding can and has been used to support models in which affixes are initially stripped before stems are accessed in the lexicon [@TaftForster1975; @ForsterAzuma2000; @StockallMarantz2006]. However, stems and affixes do also have a large frequency imbalance, with most affixes being substantially more frequent that most stems. The observation of FAE under masked priming can provide an alternative reason for why masked stem morphological priming is well attested but masked affix morphological priming is not: the latter could be due to a ceiling frequency attenuation effect. This is an intriguing possibility that must be left for future work to explore.

In summary, our study successfully replicated and expanded upon the work of @Angele2023, @Cayado2023 and @PetrosinoEtal2023, confirming the viability of observing repetition priming effects in masked priming experiments conducted online with a brief Stimulus Onset Asynchrony (SOA) of 33 ms. Notably, we addressed a lingering question in the literature by establishing the presence of the Frequency Attenuation Effect (FAE) under masked conditions. The use of large online samples proved instrumental in overcoming the longstanding challenge of insufficient statistical power to detect interactions in factorial designs, which we believe had impeded previous investigations into detecting the FAE in masked priming.

These results not only contribute to our understanding of masked priming but also open up intriguing avenues for further research. The ability to harness extensive online samples provides a valuable opportunity to explore and illuminate unresolved issues across various domains where masked priming is a crucial research tool, underscoring the potential for online experimentation to advance our knowledge and resolve long-standing questions in the field.

# References {.unnumbered}

::: {#refs}
:::

\newpage

# Wordlists {.unnumbered}

### Experiment 1 {.unnumbered}

```{r}
#| echo: false
#| message: false
#| warning: false
#| error: false 

exp1.wordlist %>% 
  left_join(., trial.means, by=join_by(word == target)) %>%
  mutate(condition = ifelse(condition=="low", md("*low frequency condition*"), 
                            ifelse(condition=='high', md("*high frequency condition*"), "non-word"))) %>%
  gt(groupname_col = "condition", process_md=T) %>%
  tab_spanner(
    label = "RT (to unrelated)",
    columns = contains("RT_unrelated")
  ) %>%
  tab_spanner(
    label = "RT (to repetition)",
    columns = contains("RT_related")
  ) %>%
  cols_label(
    unrelated = "unrelated prime",
    contains("mean") ~ "mean",
    contains("sd") ~ "SD"
  ) %>%
   sub_missing(
    missing_text = "--"
  )
  
```

### Experiment 2 {.unnumbered}

```{r}
#| echo: false
#| message: false
#| warning: false
#| error: false 

exp2.wordlist %>% 
  left_join(., trial.means_exp2, by=join_by(word == target)) %>%
  mutate(condition = ifelse(condition=="low", md("*low frequency condition*"), 
                            ifelse(condition=='high', md("*high frequency condition*"), "non-word"))) %>%
  gt(groupname_col = "condition", process_md=T) %>%
  tab_spanner(
    label = "RT (to unrelated)",
    columns = contains("RT_unrelated")
  ) %>%
  tab_spanner(
    label = "RT (to repetition)",
    columns = contains("RT_related")
  ) %>%
  cols_label(
    unrelated = "unrelated prime",
    contains("mean") ~ "mean",
    contains("sd") ~ "SD"
  ) %>%
   sub_missing(
    missing_text = "--"
  )
  
```
