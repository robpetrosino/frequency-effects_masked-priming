{
  "hash": "8bd1ceaf603c3e35bf8202a1f9df5c2a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"The detection and accurate estimation of frequency attenuation effects in masked repetition priming: A large scale web browser-based study\"\nformat:\n  tandf-pdf:\n    keep-tex: true\n    include-in-header:\n      text: |\n        \\usepackage{lscape}\n        \\newcommand{\\blandscape}{\\begin{landscape}}\n        \\newcommand{\\elandscape}{\\end{landscape}}  \n  tandf-html: default\nauthor:\n  - name: Roberto Petrosino\n    affiliations:\n      - ref: NYUAD\n    orcid: 0000-0002-8502-3070\n    email: roberto.petrosino@nyu.edu\n  - name: Diogo Almeida\n    affiliations:\n      - ref: NYUAD\n    orcid: 0000-0003-4674-8092\n    email: diogo@nyu.edu\naffiliations:\n  - id: NYUAD\n    name: New York University Abu Dhabi\n    department: Psychology Program, Division of Science\n    address: New York University Abu Dhabi\n    city: Abu Dhabi\n    country: United Arab Emirates\n    postal-code: 129188\nabstract: |\n  This study investigates the controversy surrounding the sensitivity of masked repetition priming to word frequency: while unmasked priming exhibits a frequency attenuation effect, wherein high frequency words yield smaller repetition effects, this phenomenon has been inconsistently reported in masked priming. We conducted two large online experiments with rigorously validated frequency databases to reconcile past discrepancies. The first experiment confirmed the viability of conducting masked priming experiments in web browser-based settings. The pre-registered second study, designed for high statistical power and precision, identified a 10-ms attenuation effect under masked priming. This result suggests that the repetition effect in masked priming is less qualitatively distinct from unmasked priming than previously assumed. This finding has implications for masked priming experimental design and theoretical consequences for models of priming. Crucially, models that predict either the presence or absence of frequency attenuation under masked conditions need to account for a small but reliable effect.\nkeywords: \n  - masked repetition priming\n  - frequency attenuation effect\n  - online browser-based experiment\n  - power analysis\nbibliography: references.bib  \neditor: \n  markdown: \n    wrap: 72\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n# Introduction {#sec-intro}\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.4     v tibble    3.2.1\nv lubridate 1.9.3     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(knitr)\nlibrary(gt)\nlibrary(gtExtras)\nlibrary(zoo)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'zoo'\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(here)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nhere() starts at /Users/rp3650/Library/CloudStorage/GoogleDrive-robpetrosino@gmail.com/My Drive/Academics/projects/morphology/morphological-decomposition/sub-projects/frequency-effects/frequency-effect_masked-priming\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nwd <- getwd()\ndata_filename <- \"frequency-effects_data.RData\"\n\n## check if the RData file (with all the variables) exists. If not, download it from OSF.\nif (!file.exists(here(wd, data_filename))) {\n  osf_retrieve_file(\"mz42h\") |> \n    osf_download(path = here(wd),\n                 conflicts = \"overwrite\") \n}\n\n## Load the data\ndata <- here(wd, data_filename) |> load()\n```\n:::\n\n\n\nThe masked priming technique has been an invaluable tool in visual word recognition research. It has allowed researchers to study the conditions under which orthographic, phonological, morphological, and semantic information impact access to visual word forms while mitigating strategic effects and minimizing the influence of controlled processes [@Forster1998]. First introduced in its traditional form by @ForsterDavis1984 [see also @EvettHumphreys1981], this technique involves a forward mask (i.e., usually a string of hashes, #####), followed by a prime string presented for very short time ($SOA < 60$ ms), and a target string presented immediately after. Because the prime presentation is so brief and masked by preceding and subsequent stimuli, most participants report not being aware that a prime string has been presented, and can at most report a screen flicker just before the target presentation [@ForsterEtal2003].\n\nAmong possible manipulations of prime-target relatedness, masked repetition priming (in which the same word is presented as both the prime and target within the same trial: e.g., *love-LOVE*) has been well studied, because its response seems to be qualitatively different from the unmasked counterpart ($SOA > 60 ms$): while high-frequency words benefit less from repetition than low-frequency words in the unmasked design [*frequency attenuation effect*, henceforth FAE\\; @ScarboroughEtal1977], this does not seem to be the case when the prime is masked [@ForsterDavis1984; @ForsterEtal1987; @SeguiGrainger1990; @Sereno1991; @ForsterDavis1991; @RajaramNeely1992; @BodnerMasson1997; @ForsterEtal2003; @Nievas2010].\n\nThis asymmetry in sensitivity to lexical frequency between the masked and unmasked repetition priming responses has been important in distinguishing among different models of priming in visual word recognition. More specifically, _interactive activation models_ [@McClellandRumelhart1981; @GraingerJacobs1996; @ColtheartEtal2001] conceive of priming as a \"head start\" in processing due to the pre-activation of the target word due to the presentation of the prime. Thus, according to _interactive activation_ models, priming is ultimately caused by a single mechanism, making the qualitatively different profiles for repetition priming in masked and unmasked conditions a difficult empirical finding to explain.\n\nSimilarly, episodic models [e.g., @Jacoby1981; @Jacoby1983] posit a different single mechanism for priming effects: the activation/retrieval of the episodic memory trace of the encounter with the prime word. These models therefore encounter the same type of difficulty in accounting for qualitatively different patterns of repetition priming effects in masked and unmasked conditions. A similar type of model, called the _memory recruitment model_ makes very similar predictions to the episodic memory models, positing a non-lexical source for priming effects [@BodnerMasson1997; @MassonBodner2003; @Bodner2014]. Repetition priming effects under this view stem from the exploitation, strategically or automatically, of a memory resource created by the encounter with the prime word. The frequency attenuation effect, under episodic and memory recruitment models alike, is predicted on the basis that low frequency primes, being more distinctive stimuli, create a more potent and effective memory resource compared to high frequency primes.\n\nIn contrast, other models appear to successfuly sidestep the problem posed by the qualitatively different repetition priming profiles observed in masked and unmasked conditions. One such model is the _entry-opening model_ [also known as the _bin model_\\; @ForsterDavis1984]. According to this model, when the visual stimulus is presented, lexical entries are assigned to specific bins based on orthographic similarity. In the first stage (fast search stage), a fast, frequency-ordered search goes through the entries within a given bin, and compares each one with the the input stimulus, assigning to each entry a goodness-of-fit score. This comparison is fast and crude, and sorts entries into (a) perfect (i.e., no difference is detected between the input and the entry), (b) close (i.e., small differences are detected), and (c) irrelevant matches (i.e., substantial difference are detected). Any entry of type (a) or (b) is opened, so that the entry can be further analyzed and compared to the input in the subsequent verification stage. Under a masked presentation, the entry of the prime word is opened at the fast search stage, but the short duration of the stimulus prevents it from reaching the evaluation stage. Crucially, the entry is nonetheless left open. Upon the presentation of the target stimulus, the access procedure will follow its two stage course, with a frequency-sensitive fast search and a subsequent entry opening for evaluation/verification. In this view, the fast search for the target word proceeds normally, but the evaluation/verification procedure starts and ends sooner than it otherwise would, because the target entry has already been left open after the brief processing of the prime. Thus, the _entry-opening model_ explains the masked repetition priming as the benefit from having the entry of the target word already open by the time the second stage of recognition starts. Crucially, this occurs *after* the target word is initially accessed, which happens in order of frequency. Put differently, according to the _entry-opening model_, masked repetition priming occurs because of the time savings from not having to open the entry, which is a frequency-insensitive process (i.e., every entry takes the same time to be opened), but *after* the frequency-sensitive first access stage. As a consequence, the _entry-opening model_ predicts a frequency-insensitive masked repetition priming effect, which is what has been traditionally reported in the literature (see @tbl-litReview). In addition, it also (correctly) predicts that pseudowords should not benefit from masked repetition priming, as they have no entries in the mental lexicon to be left open after the brief processing of the prime.\n\n```{.content-hidden}\nNOTE: decided to remove footnote about SOA. This is background knowledge that does not need to be explained, I think: ^[*SOA: Stimulus Onset Asynchrony*, i.e. the time between the start of one stimulus (in our case, the prime stimulus) and the start of another stimulus (the target stimulus). In the standard repetition priming design, no backward mask occurs between the prime and the target, and therefore SOA equals the duration of prime presentation.]\nNOTE: DECIDED TO REMOVE DISCUSSION OF BAYESIAN READER. This is basically because the predictions of this model are really unclear for the FAE. On the one hand, the model claims that masked priming occurs because the prime and target are treated as the same event, which predicts simply a frequency effect, but no interaction with repetition. However, Norris & Kinoshita (2008) do report the FAE, and it seems that their simulations of the model do predict a small FAE. However, they never explain this, or make this prediction explicit. They only say that they replicated the results from Kinoshita 2006 and leave it at that. In their 2018 EEG paper, they do not obtain an FAE behaviorally, but they seem indifferent to it. In none of the papers from Bayesian reader it seems that the FAE is actually discussed. The closest we get is in one paper I need to remember where they claim that a mix of high and low frequency words will create underestimates for the priors of frequent words and overestimates for priors of low frequency words. We can always add all these caveats if a reviewer wants it.\n##-----\nFinally, a more recent model called the Bayesian Reader (CITATION: Norris, 2006) conceives of visual word perception as a Bayesian inference problem, and is thus highly sensitive to task demands, as different tasks generate different perceptual hypotheses to be tested. When it comes to the frequency attenuation effect in masked priming, the predictions of the model are a little unclear. On the one hand, the Bayesian Reader model posits that under masked priming, the perceptual system is \"tricked\" into treating the prime and target presentations as a single event.  \n##-----\n, but only when the frequency counts of @BrysbaertNew2009 are used, and caution that\n##-----\nWe take this as evidence that *Labvanced* is able to consistently present stimuli at short durations. Prime duration fluctuations were however observed, and they were likely due to external factors outside of experimenter control (such as computer hardware, internet connection speed, and number of active operations in the background). \n```\n\n```{.content-hidden}\nis not easy to explain, as it seems to hint at two different mechanisms that are activated accordingly. In persisting activation models [@McClellandRumelhart1981; @GraingerJacobs1996; @ColtheartEtal2001], priming is seen as the \"head start\" effect that the prior presentation of the prime gives to the activation of the target. Therefore, regardless of the prime-target SOA, the priming magnitude is expected to be either inversely proportional to word frequency, especially if word frequency is encoded in terms of changes in connection strengths (or activation thresholds). In memory recruitment models [a.o., @BodnerMasson1997; @MassonBodner2003], priming is seen as the effect whereby the prior recruitment of the memory representation of the prime assist with the identification of the memory representation of the target. Similar to persistent activation models, memory recruitment models predict that, whatever the SOA is, the priming magnitude and word frequency inversely interact, since word frequency is encoded as episodic distinctiveness. As the episodic representations of low-frequency words are more distinctive (because they are by definition less heard and used), they would trigger a greater response than the high-frequency words. In contrast, in \n```\n\nHowever, as @tbl-litReview shows, there are nonetheless a few studies that do report significant FAEs in masked repetition priming [@BodnerMasson2001; @Kinoshita2006; @NorrisKinoshita2008, @Nievas2010]. @BodnerMasson2001 argues that when stimuli are presented in alternating case (e.g., _pHoNe_), this increases the lexical decision difficulty and therefore generates an extra incentive to draw on the memory resource created by the brief processing of the prime. Under such conditions, they were able to observe a statistically significant FAE.\n\nIn the same vein, @Kinoshita2006 noticed that in earlier studies the low frequency words often had very high error rates, and suggested that perhaps many participants did not know them. If participants treated a substantial number of low frequency words as nonwords, and nonwords do not exhibit repetition priming under masked conditions, it could artificially depress the repetition priming effect for the low frequency condition alone, which could make any existing FAE harder to detect. In two separate experiments, @Kinoshita2006 showed that larger repetition priming effects for low frequency words were only obtained when the low frequency words were vetted to make sure the participants knew them prior to the experiment. Following up on @Kinoshita2006, @NorrisKinoshita2008 were also able to find an interaction between lexical frequency and repetition in masked repetition priming, as was @Nievas2010 in Spanish (exp. 1B).\n\nFinally, as @tbl-litReview shows, it is noteworthy that 15 out of 18 previous studies showed numerically larger masked priming effects for low frequency words as opposed to high frequency words, irrespective of statistical significance. Similarly, the average repetition effect for low frequency words in the studies reviewed in @tbl-litReview is 13 ms larger when compared to that of high frequency words. These results are not in line with the predictions dictated by the _entry opening model_, and seem to align better with the predictions made by _interactive activation models_ and _memory recruitment_ models.\n\n\\blandscape\n\\small\n\n\n::: {#tbl-litReview .cell tbl-cap='Summary of the masked repetition priming effects as a function of word frequency reported in the literature. The statistical power range estimates were calculated by simulation with the corresponding sample size (N) and for two representative FAE magnitudes. Simulations were performed across a range of correlation values between conditions (from 0.6 to 0.9, in increments of 0.1) as well as plausible standard deviations per conditions (from 60 ms to 180 ms, in increments of 10 ms), with 10,000 simulated datasets for each combination of parameters.'}\n\n```{.r .cell-code .hidden}\nlit_effects %>%\n  left_join(., power_estimates_15, by=join_by(\"N\" == \"nsubj\"), multiple=\"first\") %>%\n  left_join(., power_estimates_30, by=join_by(\"N\" == \"nsubj\"), multiple=\"first\", suffix = c(\"_15\", \"_30\")) %>%\n  mutate(across(MOP_HF:MOP_Interaction, as.numeric)) %>%\n  #group_by(N) %>%\n  gt(rowname_col = \"PAPER\") %>%\n  #tab_options(row.striping.include_table_body = FALSE) %>% \n  tab_stubhead(label = \"Study\") %>%\n  tab_spanner(\n    label = \"MOP (ms)\", columns = c(MOP_HF, MOP_LF)\n  ) %>% \n  tab_spanner(\n    label = \"FAE (ms)\", columns = c(MOP_Interaction, `p<.05?`)\n  ) %>%\n  tab_spanner(\n    label = \"Power range [min max]\", columns = c(`Power range_15`, `Power range_30`)\n  ) %>%\n  cols_label( LANGUAGE = \"Language\", \n              PRIME_DURATION = \"SOA\",\n              MOP_HF = \"HF\", \n              MOP_LF = \"LF\", \n              MOP_Interaction = \"ES\",\n              `p<.05?` = md(\"_p_<.05?\"),\n              `Power range_15` = \"FAE=15ms\",\n              `Power range_30` = \"FAE=30ms\"\n  ) %>%\n  grand_summary_rows(\n    columns = c(MOP_HF, MOP_LF, MOP_Interaction),\n    fns = list(Mean ~ round(mean(.)),\n               SD ~ round(sd(.))), \n    missing_text = \" \" \n  ) %>%\n  grand_summary_rows(\n    columns = c(MOP_Interaction),\n    fns = list(Correlation ~ round(cor(MOP_HF, MOP_LF), 2)), \n    missing_text = \" \" \n  ) %>%\n   sub_missing(\n    missing_text = \" \"\n  ) %>%\n  tab_footnote( \n    footnote = \"SOA for each subject determined by pre-test\", \n    locations = cells_body(column = \"PRIME_DURATION\", rows = 14)\n  ) %>%\n  tab_footnote(\n    footnote = \"Reported in Masson & Bodner (2003)\",\n    locations = cells_stub(rows = 16) \n  )\n```\n\n::: {.cell-output-display}\n\\setlength{\\LTpost}{0mm}\n\\begin{longtable}{l|lrlrrrrll}\n\\toprule\n\\multicolumn{1}{l}{} &  &  &  & \\multicolumn{2}{c}{MOP (ms)} & \\multicolumn{2}{c}{FAE (ms)} & \\multicolumn{2}{c}{Power range [min max]} \\\\ \n\\cmidrule(lr){5-6} \\cmidrule(lr){7-8} \\cmidrule(lr){9-10}\n\\multicolumn{1}{l}{Study} & Language & N & SOA & HF & LF & ES & \\emph{p}\\textless{}.05? & FAE=15ms & FAE=30ms \\\\ \n\\midrule\\addlinespace[2.5pt]\nForster, Davis, Schoknecht, \\& Carter (1987), exp. 1 & English & 16 & 60 & 61 & 66 & 5 &   & [0.02 0.24] & [0.04 0.84] \\\\ \nNorris, Kinoshita, Hall, \\& Henson (2018) & English & 16 & 50 & 38 & 51 & 13 &   & [0.02 0.24] & [0.04 0.84] \\\\ \nSereno (1991), exp. 1 & English & 20 & 60 & 40 & 64 & 24 &   & [0.02 0.33] & [0.04 0.92] \\\\ \nForster \\& Davis (1991), exp. 5 & English & 24 & 60 & 54 & 72 & 18 &   & [0.02 0.4] & [0.05 0.96] \\\\ \nBodner \\& Masson (1997), exp. 1 & English & 24 & 60 & 29 & 45 & 16 &   & [0.02 0.4] & [0.05 0.96] \\\\ \nBodner \\& Masson (1997), exp. 3 & English & 24 & 60 & 36 & 50 & 14 &   & [0.02 0.4] & [0.05 0.96] \\\\ \nForster, Mohan, \\& Hector (2003), exp. 1 & English & 24 & 60 & 63 & 60 & -3 &   & [0.02 0.4] & [0.05 0.96] \\\\ \nKinoshita (2006), exp. 1 & English & 24 & 53 & 32 & 38 & 6 &   & [0.02 0.4] & [0.05 0.96] \\\\ \nKinoshita (2006), exp. 2 & English & 24 & 53 & 29 & 59 & 30 & * & [0.02 0.4] & [0.05 0.96] \\\\ \nNorris \\& Kinoshita (2008), exp. 1 & English & 24 & 53 & 35 & 66 & 31 & * & [0.02 0.4] & [0.05 0.96] \\\\ \nForster, Davis, Schoknecht, \\& Carter (1987), exp. 4 & English & 27 & 60 & 34 & 25 & -9 &   & [0.03 0.46] & [0.05 0.98] \\\\ \nForster \\& Davis (1984), exp. 1 & English & 28 & 60 & 45 & 38 & -7 &   & [0.03 0.48] & [0.06 0.98] \\\\ \nNievas (2010), exp. 1b & Spanish & 30 & 50 & 44 & 65 & 21 & * & [0.03 0.52] & [0.06 0.99] \\\\ \nNievas (2010), exp. 2a & Spanish & 30 & 50 or 33\\textsuperscript{\\textit{1}} & 51 & 58 & 7 &   & [0.03 0.52] & [0.06 0.99] \\\\ \nSegui \\& Grainger (1990), exp. 4 & French & 36 & 60 & 42 & 45 & 3 &   & [0.03 0.63] & [0.07 1] \\\\ \nBodner \\& Masson (2001), exps. 2A, 2B, 3, \\& 6 (average)\\textsuperscript{\\textit{2}} & English & 40 & 60 & 37 & 69 & 32 & * & [0.03 0.68] & [0.08 1] \\\\ \nRajaram \\& Neely (1992), exp. 1 & English & 48 & 50 & 30 & 37 & 7 &   & [0.04 0.76] & [0.09 1] \\\\ \nRajaram \\& Neely (1992), exp. 2 & English & 48 & 50 & 45 & 78 & 33 &   & [0.04 0.76] & [0.09 1] \\\\ \n\\midrule \n\\midrule \nMean &   &   &   & 41 & 55 & 13 &   &   &   \\\\ \nSD &   &   &   & 10 & 14 & 13 &   &   &   \\\\ \nCorrelation &   &   &   &   &   & 0.46 &   &   &   \\\\ \n\\bottomrule\n\\end{longtable}\n\\begin{minipage}{\\linewidth}\n\\textsuperscript{\\textit{1}}SOA for each subject determined by pre-test\\\\\n\\textsuperscript{\\textit{2}}Reported in Masson \\& Bodner (2003)\\\\\n\\end{minipage}\n\n:::\n:::\n\n\n\\elandscape\n\n# The present study {#sec-study}\n\nIt is somewhat surprising that the status of the FAE in masked priming remains largely unresolved in the literature, given its non-negligible average magnitude across studies and its theoretical significance in elucidating the underlying cognitive processes of masked priming.\n\nOne possible interpretation of the conflicting past findings revolves around the fact that only 4 out of 18 studies demonstrate a statistically significant FAE. Notably, this number potentially diminishes further when considering that, among these four studies, the FAE is detected only through the pooling of data across multiple studies employing a unique alternating-case stimulus presentation [@BodnerMasson2001; @MassonBodner2003]. This line of reasoning suggests a qualitatively distinct profile between masked and unmasked repetition priming, with the FAE more firmly established in the latter.\n\nConversely, one could argue that 15 out of 18 studies exhibit numerically larger repetition effect sizes for low-frequency words compared to high-frequency words —- a pattern that is challenging to reconcile with a genuine absence of interaction between frequency and masked repetition. Additionally, the average FAE across all studies stands at 13 ms, a modest yet non-negligible effect size. In fact, the naïve assumption that the two conditions are similar enough across experiments could justify the use of a *t*-test with statistically significant results: *M_FAE* = 13, CI_95% = [7, 20]), *t*(17) = 4.24, $p=.0005$. These considerations suggest that a genuine FAE may exist in masked priming but might be smaller than the magnitudes that are statistically detectable in most previous experiments. This interpretation is supported by the results from @Adelman2014 in a large scale, multi-site lab-based study on orthographic priming. They report a small but reliable FAE, but caution this effect could simply be an orthographic neighborhood effect masquerading as a frequency effect, due to the high correlations between the two variables. \n\nIn addition, another potential contributor to past discrepancies is the reliance on the dated @KuceraFrancis1967 word frequency database, which 15 out of 18 studies have depended on. This poses a potential problem, as this frequency database has consistently demonstrated inferior predictive performance in psycholinguistic experiments, particularly with low-frequency words, compared to more contemporary databases [@Burgess1998; @Zevin2002; @Balota2004; @BrysbaertNew2009; @Yap2009; @Brysbaert2011; @Gimenes2016; @Herdaugdelen2017; @Brysbaert2018]. Both of these issues are addressed in the subsequent sections.\n\n## Issues with frequency databases {#sec-study-freq}\n\nDue to the well-documented concerns over the reliability of the @KuceraFrancis1967 frequency database for psycholinguistic experiments [@Burgess1998; @Zevin2002; @Balota2004; @BrysbaertNew2009; @Yap2009; @Brysbaert2011; @Gimenes2016; @Herdaugdelen2017; @Brysbaert2018], our studies exclusively sourced materials from the HAL [@LundBurgess1996] and SUBTLEX$_{US}$ [@BrysbaertNew2009] databases, which reflect more recent linguistic usage and offer better validation in behavioral experiments [e.g., @Balota2004; @BrysbaertNew2009; @Yap2009; @Brysbaert2011; @Gimenes2016; @Herdaugdelen2017]. While these databases outperform @KuceraFrancis1967 in predicting psycholinguistic task outcomes, it is important to note potential discrepancies in individual frequency counts, particularly in the low and mid-frequency ranges. It is possible that this variation, attributable to the primary genre of their sources (USENET groups for HAL and movie subtitles for SUBTLEX$_{US}$),[^frequency-databases] may not have an oversized impact on megastudies with very large word samples [e.g., @Balota2004; @BrysbaertNew2009; @Yap2009; @Brysbaert2011; @Gimenes2016; @Herdaugdelen2017]. However, corpus-specific frequency skew can become significant when dealing with smaller samples of words, as is the case in most masked priming studies (cf. @Adelman2014). @tbl-exFreqSkew illustrates the potential discrepancy in considering words as high or low frequency based on the different aforementioned databases.\n\n[^frequency-databases]: A separate, though relevant issue which cannot be addressed here is to how to mitigate the discrepancies across the databases available, but see @Yap2009, and @Brysbaert2011 for proposals about combining the frequency counts from different corpora.\\label{fn-databases}\n\n\n\n::: {#tbl-exFreqSkew .cell tbl-cap='Example of frequency count imbalances (in occurrences per million) across the frequency norms of Kucera & Francis (KF), HAL and SUBTLEX~US~ for 4 to 6 letter words.'}\n\n```{.r .cell-code .hidden}\nfreqSkew %>% \n  gt() %>%\n  cols_label(\n    `SUBTLEX-US` = md(\"SUBTLEX~US~\")\n  ) %>%\n  fmt_number(decimals = 0, drop_trailing_zeros = TRUE) %>%\n  tab_row_group(\n    label = md(\"_Skew in KF_\"),\n    rows = 1:5\n  ) %>%\n  tab_row_group(\n    label = md(\"_Skew in HAL_\"),\n    rows = 6:10\n  ) %>%\n  tab_row_group(\n    label = md(\"_Skew in SUBTLEX~US~_\"),\n    rows = 11:15\n  ) %>%\n  row_group_order(groups = c(\"_Skew in KF_\", \"_Skew in HAL_\", \"_Skew in SUBTLEX~US~_\"))\n```\n\n::: {.cell-output-display}\n\\begin{longtable}{lrrr}\n\\toprule\nWord & KF & HAL & SUBTLEX\\textsubscript{US} \\\\ \n\\midrule\\addlinespace[2.5pt]\n\\multicolumn{4}{l}{\\emph{Skew in KF}} \\\\ \n\\midrule\\addlinespace[2.5pt]\nnegro & $104$ & $3$ & $5$ \\\\ \npoet & $99$ & $9$ & $9$ \\\\ \nmercer & $71$ & $4$ & $2$ \\\\ \nswung & $48$ & $3$ & $2$ \\\\ \nmantle & $48$ & $8$ & $2$ \\\\ \n\\midrule\\addlinespace[2.5pt]\n\\multicolumn{4}{l}{\\emph{Skew in HAL}} \\\\ \n\\midrule\\addlinespace[2.5pt]\nweb & $6$ & $351$ & $9$ \\\\ \nuser & $4$ & $297$ & $2$ \\\\ \nmint & $7$ & $211$ & $5$ \\\\ \nformat & $9$ & $198$ & $1$ \\\\ \nwarp & $4$ & $125$ & $5$ \\\\ \n\\midrule\\addlinespace[2.5pt]\n\\multicolumn{4}{l}{\\emph{Skew in SUBTLEX\\textsubscript{US}}} \\\\ \n\\midrule\\addlinespace[2.5pt]\ndaddy & $4$ & $16$ & $185$ \\\\ \nbitch & $6$ & $24$ & $169$ \\\\ \ncute & $5$ & $28$ & $88$ \\\\ \npardon & $8$ & $12$ & $65$ \\\\ \nsteal & $5$ & $28$ & $53$ \\\\ \n\\bottomrule\n\\end{longtable}\n\n:::\n:::\n\n\n\n## Issues with statistical power {#sec-study-power}\n\nThe inconsistency of past findings regarding the FAE in masked priming has been linked to a potential lack of statistical power in previous research [@BodnerMasson1997; @BodnerMasson2001; @MassonBodner2003; @Adelman2014]. This is a reasonable concern, as interactions like the FAE often require larger sample sizes for statistical detection [@PotvinSchtuz2000; @BrysbaertStevens2018] compared to main effects. We outline below three ways in which neglecting statistical power might frustrate our understanding of FAE in masked repetition priming.\n\nFirst, our literature review revealed crucial gaps in the reporting of relevant statistical information, which impedes the assessment of the statistical power attained by past experiments. The inconsistent reporting of each conditions' standard deviations (in only 7 out of 18 studies) and the complete absence of reporting of the correlation structure between conditions complicates power assessments. Researchers are thus forced to explore a range of plausible values for standard deviations and correlation structures on their own.\n\n@tbl-litReview details our attempt to conduct power simulations for two hypothesized frequency attenuation effect sizes: 15 ms (close to the averaged FAE of 13 ms) and 30 ms (close to the only three observed statistically significant FAE in English). Standard deviations (ranging between 60 ms and 180 ms, in 10 ms increments) and correlation between conditions (uniformly set to range between 0.6 and 0.9, with 0.1 unit increments) were simulated for each study's sample size, with 10,000 replications for each simulation. These range of values were derived from our literature review and previous in lab and online experiments [@Petrosino2020; @PetrosinoEtal2023]. For each simulated dataset, a paired _t_-test was performed comparing the repetition effect for high frequency words and low frequency words. This calculation is mathematically identical to the interaction term in a 2x2 factorial repeated-measures design^[the resulting *t* value, when squared, is equal to the *F* value for the interaction calculated in the 2x2 repeated-measures ANOVA), but it is less computationally expensive to perform in large scale simulations. Power to detect this interaction was then calculated as the proportion of statistically significant tests (\\alpha = 5%) obtained across replications. All else being equal, standard deviations and correlations between conditions have opposite effects on statistical power: increases in standard deviations lead to less power, while increases in correlation between conditions lead to more power.\n\nThe results reported in @tbl-litReview reveal a wide range of possible statistical power attained by previous studies, depending solely on the combination of plausible standard deviation and correlation across conditions. For instance, the study with the smallest sample size [@ForsterEtal1987, _N_=16] had a 2% to 24% chance of detecting a 15 ms frequency attenuation effect and a 4% to 84% chance to detect a 30 ms effect. Similarly, the study with the largest sample size [@RajaramNeely1992, _N_=48] exhibited a range of 4% to 76% for a 15 ms frequency attenuation effect and 9% to 100% for a 30 ms effect. As a consequence of the limited reporting of relevant statistical information in past studies, it is nearly impossible to determine if any of them were adequately powered to detect the effect of interest.\n\nA second concern arising from the ambiguity surrounding statistical power in the literature is the potential impact of a prevalence of low-powered experiments on the scientific record. An excess of such experiments increases the risk of observed statistically significant effects being spurious [@Button2013]. As highlighted in @tbl-litReview, only 4 out of 18 studies demonstrate a statistically significant FAE. The absence of clarity regarding the statistical power of previous research poses challenges in assessing the likelihood of these significant findings being spurious.\n\nFinally, it is widely acknowledged that experiments with approximately 50% power are akin to a coin toss in their ability to detect a true effect [@Cohen1992]. A less-appreciated fact is that, in the presence of even lower power (<25%), statistically significant results can substantially overestimate the effect size -- a type-M error [@GelmanCarlin2014]. When power drops to levels below 10%, a statistically significant result may occur even when the observed effect goes in the opposite direction of the true effect -- a type-S error [@GelmanCarlin2014]. Our power simulations for within-subjects data revealed a similar relationship between statistical power, type-M, and type-S errors in line with the observations detailed by @GelmanCarlin2014 for the independent samples $t$-test. For instance, at 10% power (a possibility for virtually all previous studies, as indicated in @tbl-litReview), a statistically significant result could indicate an overestimation of the magnitude of the frequency attenuation effect by a factor between 2 and 5, with up to a 5% chance of incorrectly determining the direction of the effect.\n\nThe two studies reported here were designed to mitigate these two confounding issues: the overreliance on the @KuceraFrancis1967 frequency data as well as a potential lack of statistical power observed in previous research. As a large increase in statistical power requires a large sample size, Experiment 1 aimed to assess the suitability of using *Labvanced* [@Labvanced2017], an online platform for running web browser-based experiments, for running masked priming studies online.\n\n\n\n# Experiment 1 {#sec-exp1}\n\n\n\nAs evident in @tbl-litReview, conducting a properly powered experiment for a FAE close to the averaged value calculated from previous studies requires a sample size that would be impractical to pursue in standard university research settings, i.e. typically quiet lab rooms with a small number of research computers. In response to this challenge, the present study was exclusively conducted online, leveraging the growing trend in online behavioral research facilitated by HTML5 capabilities and the availability of advanced web software such as *jsPsych* [@deLeeuw2014], *PsychoJS* (the JavaScript counterpart of *PsychoPy*, @PeirceEtal2019), *Gorilla* [@Anwyl2020], and *Labvanced* [@Labvanced2017]. Notably, three recent studies have already demonstrated the viability of conducting masked priming experiments online, employing different software tools: @Angele2023 with *PsychoJS*, @Cayado2023 with *Gorilla* and @PetrosinoEtal2023 with *Labvanced*. In this study, we opted for *Labvanced* [@Labvanced2017], given our previous successful experience with it [@PetrosinoEtal2023]. Similar to *Gorilla*, *Labvanced* eliminates local installation issues, ensuring cross-platform consistency and simplifying experimental design without necessitating proficiency in additional programming languages.\n\nWe determined the sample size large enough to guarantee an acceptable statistical power ($>80%$) by a full-fledged power analysis specifically targeting what we construed as the smallest theoretically interesting FAE (i.e., 5ms). The details of the power analysis is available as supplemental material of the paper. Similarly, the code used for the power simulations, along with the simulated datasets are available online (<https://osf.io/r7d2q/>). Our analysis identified a sample size of 1,250 participants as optimal, ensuring robust statistical power especially for a raw FAE equal to or exceeding 10 ms —- a value closely aligned with the average FAE calculated from previous studies (cf. @tbl-litReview). In light of the limitations in the temporal accuracy and precision of current online stimulus delivery programs (observed in several pilots and previous published studies conducted in our lab), we aimed for an intended sample size of 2,600. This decision was made to enhance the likelihood of obtaining a sample size of at least 1,250 participants after applying all the necessary exclusion criteria to the data. In addition, sample sizes exceeding 1,250 can only help increase the precision of the estimated effect size.\n\nIn this experiment, the prime duration was set at 33 ms. The motivation for the choice of such a short prime duration (as compared to the literature, in which it is usually between 50 and 60 ms; see @tbl-litReview) is threefold. First, previous experiments on *Labvanced* [@PetrosinoEtal2023] showed that, due to the inherent difficulties in presenting stimuli for very short set durations in the browser, a longer set duration would increase the number of trials in which the prime duration would rise above the subliminal threshold (usually thought to be around 60 ms) due to timing inaccuracies and missing screen refreshes, which could trigger the adoption of experiment-wide strategies in the task, and ultimately contaminate the masked priming response [@Zimmerman2012]. Second, @Angele2023, @Cayado2023 and @PetrosinoEtal2023 have demonstrated that a 33 ms priming duration is sufficient to elicit repetition priming effects in online experiments. Finally, setting such a short prime duration prevents virtually everyone from consciously perceiving the prime word [@ForsterEtal2003, @Nievas2010], and thus presents a less contaminated estimate of early putatively automatic processes in word recognition.\n\n## Methods {#sec-exp1-methods}\n\n### Preregistration {#sec-exp1-prereg}\n\nWe preregistered the results of the power analysis, the goals, the design and analysis plan for this experiment prior to data collection. The preregistration, detailing the experimental hypotheses, the desired sample size as well as the planned analyses is available online (<https://doi.org/10.17605/OSF.IO/3NFQP>).\n\n### Participants {#sec-exp1-methods-participants}\n\nTwo thousand and six hundred participants (1,445 females; _mean age_ = 42, _sd age_ = 14) were recruited on Prolific (<https://www.prolific.com>). Several criteria were selected to ensure recruitment of native speakers of U.S. English. Participants had to be born in the Unites States of America, speak English as their first and only language, and have no self-reported language-related disorder. We encouraged participants to avoid any sort of distraction throughout the experiment, and to close any program that may be running in the background. Because the experiment was run online, participants could not be monitored during data collection. Finally, to further reduce variability across participants' devices, we restricted the experiment to be run on Google Chrome only, which is the most used browser worldwide [@w3counterGlobalStats], and reportedly performs better than any other across operating systems [likely thanks to the _Blink_ engine\\; see @LukacsGaspar2023].\n\n### Design {#sec-exp1-methods-design}\n\nThe masked priming procedure relied on a lexical decision task (LDT), in which a 2 (frequency: _high_ vs _low_) x 2 (prime type: _repetition_ vs _unrelated_) factorial design was used. Both factors were manipulated within-subjects. The dependent variables were lexical decision latency (RT, in milliseconds) and error rate (in percentages).\n\n### Materials {#sec-exp1-methods-materials}\n\nOne-hundred and four five-letter words, half of low frequency (between 7 and 24 in the SUBTLEX$_{US}$ frequency per million) and half of high frequency (between 57 and 2,961 in the SUBTLEX$_{US}$ frequency per million) were sampled from ELP [@balota2007], but this time based on the SUBTLEX$_{US}$ frequency counts rather than HAL. @tbl-words_exp1 shows that although the SUBTLEX$_{US}$ frequency ranges of the two conditions were very far from one another they still show some overlap when HAL frequencies are used. As mentioned before, this seems to be a general problem when jointly considering different frequency databases for a smaller set of stimuli that need to be manipulated and controlled in different ways (see also fn. \\ref{fn-databases} and @Adelman2014). From each condition, 26 words were selected to be presented as targets and related primes (the *repetition* condition), and the remaining 26 were presented as unrelated primes (the *unrelated* condition). All word items were also controlled for orthographic neighborhood (i.e., Coltheart's _N_): $t \\approx 0$. All words used were monomorphemic nouns, adjectives, or verbs, thus excluding particles, prepositions, and derived or inflected forms.\n\n\n\n\n::: {#tbl-words_exp1 .cell tbl-cap='Experiment 1. Descriptive statistics of the word items used. For both frequency databases, the word frequencies were converted to per-million count to ensure cross-comparison.'}\n\n```{.r .cell-code .hidden}\nwords %>%\n  group_by(freq.bin) %>%\n  mutate(Freq_HAL.Pm = (Freq_HAL * 10^6)/(131 * 10^6)) %>%\n  summarise(N = n(),\n            minFreq= min(Freq_HAL.Pm, na.rm = T), maxFreq=max(Freq_HAL.Pm, na.rm = T),\n            meanFreq = mean(Freq_HAL.Pm, na.rm = T), sdFreq = sd(Freq_HAL.Pm, na.rm = T),\n            minSUBFreq= min(SUBTLWF, na.rm = T), maxSUBFreq=max(SUBTLWF, na.rm = T),\n            meanSUBFreq = mean(SUBTLWF, na.rm = T), sdSUBFreq = sd(SUBTLWF, na.rm = T),\n            minN = min(Ortho_N, na.rm=T), maxN = max(Ortho_N, na.rm=T),\n            meanN = mean(Ortho_N, na.rm=T), sdN = sd(Ortho_N, na.rm = T)\n            #meanRT=mean(as.numeric(I_Mean_RT), na.rm = T), sdRT=sd(as.numeric(I_Mean_RT), na.rm = T),\n            #meanLength = mean(Length, na.rm = T), sdLength=sd(Length, na.rm = T)\n            ) %>% \n  mutate(across(c(3:10), round), across(11:14, round, 2))  %>% \n  #mutate_if(needs_mutated, ~round(.)) %>%\n  gt() %>%\n  cols_label(\n    freq.bin = \"frequency\", \n    minFreq = \"min\", maxFreq = \"max\", meanFreq = \"mean\", sdFreq = \"SD\", \n    minSUBFreq = \"min\", maxSUBFreq = \"max\", meanSUBFreq = \"mean\", sdSUBFreq = \"SD\",\n    minN = \"min\", maxN = \"max\", meanN = \"mean\", sdN = \"SD\") %>%\n  tab_spanner(\n    label=md(\"**HAL**\"),\n    columns=3:6\n  ) %>%\n  tab_spanner(\n    label=md(\"**SUBTLEX~US~**\"),\n    columns=7:10\n  ) %>%\n  tab_spanner(\n    label=md(\"**Orthographic _N_**\"),\n    columns=11:14\n  )\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: There was 1 warning in `mutate()`.\ni In argument: `across(11:14, round, 2)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n```\n\n\n:::\n\n::: {.cell-output-display}\n\\begin{longtable}{lrrrrrrrrrrrrr}\n\\toprule\n &  & \\multicolumn{4}{c}{\\textbf{HAL}} & \\multicolumn{4}{c}{\\textbf{SUBTLEX\\textsubscript{US}}} & \\multicolumn{4}{c}{\\textbf{Orthographic \\emph{N}}} \\\\ \n\\cmidrule(lr){3-6} \\cmidrule(lr){7-10} \\cmidrule(lr){11-14}\nfrequency & N & min & max & mean & SD & min & max & mean & SD & min & max & mean & SD \\\\ \n\\midrule\\addlinespace[2.5pt]\nhigh & 52 & 45 & 4984 & 573 & 808 & 57 & 2691 & 210 & 388 & 0 & 10 & 3.98 & 2.60 \\\\ \nlow & 52 & 6 & 570 & 64 & 93 & 7 & 24 & 13 & 5 & 0 & 11 & 3.92 & 2.79 \\\\ \n\\bottomrule\n\\end{longtable}\n\n:::\n:::\n\n\n\nOne-hundred and four five-letter, phono-orthographically legal non-words were randomly selected from the ELP database as well. Half of them (i.e., 52) were randomly selected to be presented as targets; the other half was instead used as unrelated non-word primes. None of the non-words contained any existing English morpheme. Both the words and non-words used in the experiments are reported in the appendix below. In addition, all items had a reported error rate smaller than 10%, so to ensure that they were all clearly distinguishable by participants.\n\n### Procedure {#sec-exp1-methods-proc}\n\nEach recruited participant was assigned one of two word lists, which differed only in the relatedness of the prime with respect to the target; otherwise, the two lists presented the same set of target words and nonwords (i.e., 104 pairs for each list). In one list, the three conditions (the high- and low-frequency word conditions, and the non-word condition) had half of the target items being preceded by themselves (the *repetition* condition) and half of the target items being preceded by one of the unrelated primes belonging to the same frequency bin (the *unrelated* condition). In the other list, these assignments were reversed. The order of stimulus presentation was randomized for each participant.\n\nAfter being recruited in the _Prolific_ online platform, participants were asked to click on a link redirecting them to the Labvanced online service. During the experiment, they were asked to perform a lexical decision task by pressing either the 'J' (for word) or 'F' (for non-word) keys on their keyboard. Each trial consisted of three different stimuli appearing at the center of the screen: a series of five hashes (#####) presented for 500 ms, followed by a prime word presented for 33 ms, and finally the target word; the target word disappeared from the screen as soon as a decision was made.\n\nParticipants were given 5 breaks throughout the experiment. When the experiment was over, the participants were then redirected to Prolific in order to validate their submission. The median time to finish the experiment was 6 minutes. Each participant was paid with a standard rate of GBP 9/hour.\n\n## Data analysis {#sec-exp1-analysis}\n\nAnalysis scripts and an abridged version of the data collected can be found online (<https://osf.io/vn3r2>), and consisted of 297,598 observations in total. We performed the same three steps of analysis described for experiment 1 (@sec-exp1-analysis).\n\n### Step 1: subject and item performance {#sec-exp1-analysis-performance}\n\nItem and subject error rates were calculated. The item error rate was never above 14%, so no item was excluded from analysis. 19 subjects were removed because their error rate was above 30%. Thus, a total of 269,652 observations and 2,593 participants were included in further analyses.\n\n### Step 2: prime durations {#sec-exp1-analysis-primeTime}\n\nPrime fluctuations were dealt with in the same way as in experiment 1 (@sec-exp1-analysis-primeTime). The mean (mean = 32.32 ms, sd = 15) and the median (median = 33 ms)  prime durations were closer to the intended value (33 ms). The same prime duration cut-off set for experiment 1 (i.e., any trial whose prime duration was out of the 25-60ms range) removed 13 % of the trials. No participant was excluded, for a total of 237,287 observations.\n\n### Step 3: RT analysis {#sec-exp1-analysis-RT}\n\nAfter removing the incorrect responses, similarly to experiment 1 (@sec-exp1-analysis-RT), 0.51% of the trials were excluded if their corresponding RT was below 200 ms or above 1800 ms. Finally, 249 subjects were removed because the number of trials within the same condition was less than 7 (i.e., about half of the total number of trials being presented within the same condition, i.e. 13). A total of 210,889 observations and 2,341 subjects were included in the statistical analysis below. \n\n## Results {#sec-exp1-results}\n\n@tbl-exp1-statsResults below report the descriptive statistics of the experiment. For each frequency condition, priming effects were calculated by subtracting the mean RT to the related condition to the mean RT from the unrelated condition. We ran two different analyses, for both RT and error data. First, we ran a 2x2 repeated-measures ANOVA (condition, 3 levels: high vs. low vs. non-word; primetype, 2 levels: unrelated vs. repetition) on the by-subject averaged data, paired with planned comparisons between related and unrelated primetype for each condition. In addition, a Generalized Linear Mixed Model (GLMM) analysis on the raw RT and the raw accuracy data (rather the by-subject means or error rates used in the ANOVA analyses). Unlike linear mixed-effect models, GLMMs do not assume normal distribution of the data, and are therefore particularly useful for non-normally distributed data such as RTs and accuracy. For the RT data, a Gamma distribution was used; for the accuracy data, a binomial distribution was used instead, both with an identity link between fixed effects and the dependent variable [@LoAndrews2015]. To prevent converge failure, the model was kept as simple as possibly, with condition, primetype, and their interaction as fixed effects, and subjects and items as random intercepts. Before fitting the model, the contrasts were also set to sum-to-zero contrasts (i.e., by using the R function `contr.sum()`) to facilitation interpretation of main and interaction effects. The fitting was performed by using the `lme4` R-package [@BatesEtal2015] with the Laplace approximation technique, using 1 million iterations and the BOBYQA optimizer to help convergence. Then, we used the function `Anova()` from the `car` R-package [@FoxWeisberg2019] to obtain estimates and probability values for fixed effects calculated for Type-III sums of squares. \n\nIn the word analysis, the ANOVA analysis showed significant main effects (condition: *F*(1, 2340)=1572, *p*<.0001; primetype: *F*(1, 2340)=1113, *p*<.0001) and their interaction *F*(1, 2340)=52.48, *p*<.0001). Planned comparisons confirmed statistically significant repetition priming effects for both word conditions (*MOP_HF*=18 ms, *CI_95%*=[16 20], *t*(2340)=19.7, *p*<.0001; *MOP_LF* = 28 ms, *CI_95%*=[26 30], *t*(2340)=27.8, *p*<.0001), with the low-frequency word repetition priming effect being 10 ms larger than the high-frequency word repetition priming effect. This FAE effect was statistically significant (*M_FAE*=10 ms, *CI_95%*=[7 13]), *t*(2340)=7.24, *p*<.0001l). A very small but statistically significant inhibitory priming effect was observed in the non-word condition (*MOP_NW*=-2 ms, *CI_95%*=[-4 0], *t*(2340)=-2.33, *p*<.0001). Similarly, the GLMM analysis confirmed that both main effects (condition: $\\chi^2=2978.35, p<.0001$; primetype: $\\chi^2=1531.12, p<.0001$) and their interaction ($\\chi^2=870.27, p<.0001$) were significant. \n\nIn the error analysis, the ANOVA analysis revealed significant effects for both main effects (condition: *F*(1, 2340)=392.5, *p*<.0001; primetype: *F*(1, 2340)=380.5, *p*<.0001) and interaction *F*(1, 2340)=55.47, *p*<.0001). Planned comparison revealed significant priming effects in the form of fewer errors in the repeated compared to unrelated trials in the all conditions (high: *t*(2340)=9.95, *p*<.0001; low: *t*(2340)=16.9, *p*<.0001; non-word: *t*(2340)=-3.27, *p*=.001). As in the ANOVA error analysis, both main effects (condition: $\\chi^2=30.45, p<.0001$; primetype: $\\chi^2=108.88, p<.0001$) and their interaction ($\\chi^2=307.57, p<.0001$) were significant.\n\n\\blandscape\n\n\n::: {#tbl-exp1-statsResults .cell tbl-cap='Experiment 1. Summary of the word priming results. *Legend.* MOP: magnitude of priming.' tbl-pos='h'}\n\n```{.r .cell-code .hidden}\nexp1_summary.results %>%\n  relocate(c(\"sd_unrelated\", \"mean.error_unrelated\"), .before=gd.mean_related) %>%\n  gt() %>%\n  cols_label(\n    CI = \"95% CI\",\n    contains(\"mean\") ~ \"mean\",\n    contains(\"sd\") ~ \"SD\", \n    contains(\"error\") ~ \"Error (%)\"\n  ) %>%\n  tab_spanner(\n    label = \"unrelated RT\",\n    columns = c(2:4)\n  ) %>%\n  tab_spanner(\n    label = \"repetition RT\",\n    columns = c(5:7)\n  ) %>%\n  tab_spanner(\n    label = 'priming effects',\n    columns = c(9:12)\n  ) %>%\n  tab_spanner(\n    label = md(\"_t_-test\"),\n    columns = c(13:15)\n  ) %>%\n  cols_label(\n    sd = md(\"SD~p~\")\n  ) %>%\n  cols_label(\n    t = md(\"_t_\"),\n    p = md(\"_p_\"),\n  ) %>%\n   sub_missing(\n    missing_text = \" \"\n  )\n```\n\n::: {.cell-output-display}\n\\begin{longtable}{lrrrrrrrrlrrrrl}\n\\toprule\n & \\multicolumn{3}{c}{unrelated RT} & \\multicolumn{3}{c}{repetition RT} &  & \\multicolumn{4}{c}{priming effects} & \\multicolumn{3}{c}{\\emph{t}-test} \\\\ \n\\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){9-12} \\cmidrule(lr){13-15}\nfactor & mean & SD & Error (\\%) & mean & SD & Error (\\%) & cor & MOP & 95\\% CI & SD\\textsubscript{p} & ES & \\emph{t} & df & \\emph{p} \\\\ \n\\midrule\\addlinespace[2.5pt]\nhigh & 573 & 83 & 3 & 555 & 85 & 2 & 0.860 & 18 & [16 20] & 45 & 0.41 & 19.7 & 2340 & 2.88e-80 \\\\ \nlow & 605 & 88 & 6 & 577 & 88 & 3 & 0.850 & 28 & [26 30] & 49 & 0.58 & 27.8 & 2340 & 1.52e-147 \\\\ \nnon-word & 623 & 103 & 4 & 625 & 103 & 4 & 0.910 & -2 & [-4 0] & 43 & -0.05 & -2.33 & 2340 & 0.0197 \\\\ \nfrequency:primetype &   &   &   &   &   &   & 0.029 & 10 & [7 13] & 66 & 0.15 & 7.24 & 2340 & 5.86e-13 \\\\ \n\\bottomrule\n\\end{longtable}\n\n:::\n:::\n\n\n\\elandscape\n\n## Discussion {#sec-exp1-discussion}\n\nExperiment 1 was designed to investigate whether Frequency Attenuation Effects (FAE) can be detected under masked priming conditions (with SOA = 33 ms). We managed to recruit a very large sample size ($N=2341$) to ensure adequate statistical power for detecting even small effect sizes. Our results not only showed statistically significant main effects of repetition for high and low frequency words alike, but also detected a statistically significant interaction: the low-frequency condition yielded priming effects that were 10 ms larger than the high-frequency condition with a margin of error as narrow as 5 ms. The absence of a robust non-word masked priming response has been used as an additional piece of evidence supporting the view that the masked priming response stems from lexical memory and is devoid of episodic influences [e.g., @Forster1999]. The results of this experiment align with the previous evidence in showing at best very small inhibitory masked repetition priming for non-words, with very high precision: the 95% CI indicates the plausible range for the masked repetition priming effect for non-words to be between -4 and 0 ms when prime duration is 33 ms.\n\n\n\n# Experiment 2 {#sec-exp2}\n\n\n\nThe results of experiment 1 showed that with the right sample size, the repetition priming response may indeed be modulated by word frequency. However, the experiment was carried out with a unusually short prime duration (i.e., 33 ms). In previous pilot experiments carried out at longer durations (e.g., 48 ms), we observed that the distribution of the prime duration tended to be more positively skewed, with a substantial increase of the number of trials with a prime duration above the subliminal threshold of 60 ms. While being aware of these methodological limitations, we carried out a follow-up experiment that elicited the repetition priming response to the same materials used in experiment 1, with a longer prime duration (i.e., 48 ms), which is more in line with the literature on the topic. The aim for this experiment was three-fold. From the methodological point of view, it may show that a shorter prime duration in online masked priming experiment may prevent unnecessary data loss, while still providing reliable results. From the theoretical point of view, it may provide further evidence on two separate issues. First, it may inform on the interaction between priming and prime duration. In particular, we expect the longer prime duration to elicit a larger facilitation, and therefore a larger magnitude of priming. Second, and more importantly for the question being asked here, it may further inform on the size of the interaction between priming and word frequency. \n\n## Methods {#sec-exp2-methods}\n\n### Participants {#sec-exp2-methods-participants}\n\nTwo thousand and six hundred participants (1,551 females; _mean age_ = 39, _sd age_ = 12) were recruited on Prolific (<https://www.prolific.com>) with the same criteria specified for experiment 1 (@sec-exp1-methods-participants). Prior to recruitment, the participants participating in experiment 1 were excluded from the pool, so that the participants recruited for experiment 2 was completely different from the participants recruited for experiment 1. \n\n### Design {#sec-exp2-methods-design}\n\nThe experimental design was identical to experiment 1.\n\n### Materials {#sec-exp2-methods-materials}\n\nThe experimental items were the same as experiment 1.\n\n### Procedure {#sec-exp2-methods-proc}\n\nExperiment 2 followed the same procedures as experiment 1 (see @sec-exp1-methods-proc). The median time to finish the experiment was the same as experiment 1 (i.e., about 6 minutes).\n\n## Data analysis {#sec-exp2-analysis}\n\nAnalysis scripts and an abridged version of the data collected can be found online (<https://osf.io/k3gpc>), and consisted of 295,940 observations in total. We performed the same three steps of analysis described for experiment 1 (@sec-exp1-analysis).\n\n### Step 1: subject and item performance {#sec-exp2-analysis-performance}\n\nItem and subject error rates were calculated. Similarly to experiment 1, the item error rate was never above 12%, so no item was excluded from analysis. 39 subjects were removed because their error rate was above 30%. Thus, a total of 265,982 observations and 2,558 participants were included in further analyses.\n\n### Step 2: prime durations {#sec-exp2-analysis-primeTime}\n\nPrime fluctuations were dealt with in the same way as in experiment 1 (@sec-exp1-analysis-primeTime). The mean (mean = 50.11 ms, sd = 11.13) and the median (median = 50 ms) prime durations were closer to the intended value (50 ms). The same prime duration cut-off set for experiment 1 (i.e., any trial whose prime duration was out of the 25-60ms range) removed 20 % of the trials. As compared to experiment 1, experiment 2 had therefore a 7% larger percentage of removed out-of-range trials, the majority of which (18%) were above the subliminal threshold. This is in sharp contrast with the distribution of the prime durations in experiment 1, where the trials above the range amounted to only 0% of the dataset. As observed in previous studies and pilot conducted in our lab, this distribution suggests that setting the prime duration closer to either limit of a given range has the side effect of allowing for more fluctuations around either limit, thus potentially leading to greater data loss (see also further below). No participant was excluded, for a total of 213,078 observations.\n\n### Step 3: RT analysis {#sec-exp2-analysis-RT}\n\nAfter removing the incorrect responses, similarly to experiment 1 (@sec-exp1-analysis-RT), 0.59% of the trials were excluded if their corresponding RT was below 200 ms or above 1800 ms. Finally, 634 subjects were removed because the number of trials within the same condition was less than 7 (i.e., about half of the total number of trials being presented within the same condition, i.e. 13). A total of 168,195 observations and 1,924 subjects were included in the statistical analysis below. The substantial number of subjects being removed at this final stage was the ultimate side effect of the increased number of out-of-range trials that were removed during the previous step of analysis, and provides further evidence of the risks with setting the prime duration closer to the upper bound of the subliminal range.\n\n## Results {#sec-exp2-results}\n\n@tbl-exp2-statsResults below report the descriptive statistics of the experiment. For experiment 2, we ran the same statistical analyses as experiment 1. In the word analysis, a 2x2 repeated-measures ANOVA revealed significant main effects (condition: *F*(1, 1923)=987.4, *p*<.0001; primetype: *F*(1, 1923)=1447, *p*<.0001) and interaction *F*(1, 1923)=36.82, *p*<.0001). Planned comparisons confirmed statistically significant repetition priming effects for both word conditions (*MOP_HF*=26 ms, *CI_95%*=[24 28], *t*(1923)=24.6, *p*<.0001; *MOP_LF* = 35 ms, *CI_95%*=[33 37], *t*(1923)=30.2, *p*<.0001), with the low-frequency word repetition priming effect being 10 ms larger than the high-frequency word repetition priming effect. This FAE effect was statistically significant (*M_FAE*=9 ms, *CI_95%*=[6 12]), *t*(1920)=6.07, *p*<.0001). A very small but statistically significant inhibitory priming effect was observed in the non-word condition (*MOP_NW*=-4 ms, *CI_95%*=[-6 -2], *t*(1923)=-3.53, *p*=.0004). The GLMM analysis confirmed significant effects for condition ($\\chi^2=2613.3, p<.0001$), primetype ($\\chi^2=1700.5, p<.0001$), and their interaction ($\\chi^2=1158.9, p<.0001$).\n\nIn the error analysis, the ANOVA showed significant effects for both main effects (condition: *F*(1, 2340)=392.5, *p*<.0001; primetype: *F*(1, 2340)=380.5, *p*<.0001) and interaction *F*(1, 2340)=55.47, *p*<.0001). Planned comparisons confirmed significant priming effects in the form of fewer errors in repeated compared to unrelated trials in the all conditions (high: *t*(1923)=9.30, *p*<.0001; low: *t*(1923)=15.8, *p*<.0001; non-word: *t*(1923)=-2.32, *p*=.002). Similar results were obtained in the GLMM error analysis (condition: $\\chi^2=51.50, p<.0001$; primetype: $\\chi^2=97.42, p<.0001$; interaction: $\\chi^2=283.77, p<.0001$.\n\n\\blandscape\n\n\n::: {#tbl-exp2-statsResults .cell tbl-cap='Experiment 2. Summary of the word priming results. *Legend.* MOP: magnitude of priming.' tbl-pos='h'}\n\n```{.r .cell-code .hidden}\nexp2_summary.results %>%\n  relocate(c(\"sd_unrelated\", \"mean.error_unrelated\"), .before=gd.mean_related) %>%\n  gt() %>%\n  cols_label(\n    CI = \"95% CI\",\n    contains(\"mean\") ~ \"mean\",\n    contains(\"sd\") ~ \"SD\", \n    contains(\"error\") ~ \"Error (%)\"\n  ) %>%\n  tab_spanner(\n    label = \"unrelated RT\",\n    columns = c(2:4)\n  ) %>%\n  tab_spanner(\n    label = \"repetition RT\",\n    columns = c(5:7)\n  ) %>%\n  tab_spanner(\n    label = 'priming effects',\n    columns = c(9:12)\n  ) %>%\n  tab_spanner(\n    label = md(\"_t_-test\"),\n    columns = c(13:15)\n  ) %>%\n  cols_label(\n    sd = md(\"SD~p~\")\n  ) %>%\n  cols_label(\n    t = md(\"_t_\"),\n    p = md(\"_p_\"),\n  ) %>%\n   sub_missing(\n    missing_text = \" \"\n  )\n```\n\n::: {.cell-output-display}\n\\begin{longtable}{lrrrrrrrrlrrrrr}\n\\toprule\n & \\multicolumn{3}{c}{unrelated RT} & \\multicolumn{3}{c}{repetition RT} &  & \\multicolumn{4}{c}{priming effects} & \\multicolumn{3}{c}{\\emph{t}-test} \\\\ \n\\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){9-12} \\cmidrule(lr){13-15}\nfactor & mean & SD & Error (\\%) & mean & SD & Error (\\%) & cor & MOP & 95\\% CI & SD\\textsubscript{p} & ES & \\emph{t} & df & \\emph{p} \\\\ \n\\midrule\\addlinespace[2.5pt]\nhigh & 574 & 83 & 3 & 548 & 83 & 2 & 0.850 & 26 & [24 28] & 46 & 0.56 & 24.595576 & 1923 & 2.27e-116 \\\\ \nlow & 605 & 89 & 6 & 570 & 89 & 3 & 0.840 & 35 & [33 37] & 51 & 0.69 & 30.185474 & 1923 & 3.51e-164 \\\\ \nnon-word & 629 & 108 & 4 & 633 & 110 & 5 & 0.900 & -4 & [-6 -2] & 50 & -0.08 & -3.525726 & 1923 & 4.32e-04 \\\\ \nfrequency:primetype &   &   &   &   &   &   & 0.024 & 9 & [6 12] & 68 & 0.13 & 6.068254 & 1923 & 1.55e-09 \\\\ \n\\bottomrule\n\\end{longtable}\n\n:::\n:::\n\n\n\\elandscape\n\n## Discussion {#sec-exp2-discussion}\n\nExperiment 2 was designed to investigate whether a frequency attenuation effect akin to the one detected in experiment 1 at SOA of 33 ms can be detected at the longer, and most commonly used SOA of 48 ms. To this end, we used the same stimuli and recruited the same sample size as experiment 1, and only set the prime duration accordingly. First, we found that the masked repetition priming to both high and low-frequency words were respectively about 8 ms larger in experiment 2 than in experiment 1, resulting from the longer prime duration [@ForsterEtal2003]. Nevertheless, the significant interaction effect size amounted to 9 ms, which is only 1 ms away from the estimate of the interaction in experiment 1 (10 ms), but well within its 95% CI (which ranged from 7 ms to 13 ms). Finally, similarly to experiment 1, the magnitude of non-word masked repetition priming response in experiment 2 was inhibitory, though slightly larger (-4 ms, as compared to -2 ms of experiment 1).\n\nAt the face value, experiment 2 is very similar to experiment 1 on several respects. First, they involved the exact the same stimuli and the same sample size from the same pool (i.e., the Prolific pool; crucially though, different participants were recruited for each experiment). Second, they were both analyzed with the exact same analysis pipeline, and, in particular, with the same criterion to detect trials with outlying prime durations. Third, the estimates (means, SDs, error percentages, and correlations) of both experiments are numerically very close to one another, with the maximal differences almost exclusively present in the repetition conditions. For these reasons, one may therefore argue against its methodological and theoretical validity, and may deem the differences of the magnitude of priming across the two experiments might have just been due to sampling error having two major sources. The first source of sampling error is the inherent imprecision in the presentation of the prime. Regardless of the preset duration of the prime, there was an inherent inaccuracy in the actual presentation of the prime in both experiments. The analysis pipeline (and, in particular, with the criterion to detect trials with outlying prime durations) described in detail above might have therefore led to two datasets with a similar distribution of the prime durations. @fig-prime-distributions shows the distributions of the prime durations for both datasets after the last analysis step. The two distributions minimally overlap, with most of the trials peaking at about the relative preset duration (i.e., 33 and 48 ms). The difference between the two distribution was also statistically significant: $t(394431)=-868.47, p<.0001$.\n\n\n\n::: {#cell-fig-prime-distributions .cell}\n\n```{.r .cell-code .hidden}\nexps_data_final <- bind_rows(exp1_data_final_with.errors, exp2_data_final_with.errors, .id='experiment') %>%\n  mutate(experiment = factor(experiment))\n\nexps_data_final %>% #filter(experiment==\"1\") %>%\n  ggplot(aes(x=primeTime, color=experiment, fill=experiment))+\n  geom_histogram(binwidth=1, alpha=0.2, position = \"nudge\")+\n  #geom_density(alpha=0.2, bw=0.7) + #if we want smooth curves\n  theme_bw() + \n  theme(panel.grid.major = element_blank(),\n      panel.grid.minor = element_blank(), \n      panel.border = element_blank(),\n      legend.position=\"bottom\") +\n  scale_x_continuous() +\n  labs(x = \"prime duration\", y = \"number of trials\")\n\nexps_prime.durations_tTest <- t.test(primeTime ~ experiment, data=exps_data_final, var.equal=T)\n```\n\n::: {.cell-output-display}\n![Distribution of the prime durations across the two experiments.](index_files/figure-pdf/fig-prime-distributions-1.pdf){#fig-prime-distributions fig-pos='H'}\n:::\n:::\n\n\n\nThe second source of sampling error is equally unavoidable and present in every study: participant selection, and is ensured by the fact that recruiting sample sizes approaching infinity is virtually impossible. One way to gauge the extent to which such source of sampling error might have affected the differences in the effect sizes of the two experiments is to calculate the _prediction intervals_ on the results of experiment 1, and check if the results of experiment 2 fall within them. Unlike confidence intervals, the lesser-known prediction intervals are calculated around the original study's mean (rather than the population mean), and express the amount of deviation that a future replication of the study may allow for due to sampling error [@SpenceStanley2016]. In our case, if the results of experiment 2 falls within the prediction interval above, it would suggest that the deviation between the two experiment was just due to sampling error, and therefore experiment 2 is a replication of experiment 1. Conversely, if the results of experiment 2 falls within the prediction interval above, it would suggest that the deviation between the two studies could not be due to sampling error, and therefore experiment 2 is not a replication of experiment 1. The prediction intervals for the means of the three conditions and the interaction between the two word condition (i.e., FAE) of experiment 1 were calculated by using the function `pi.m()` of the R package `predictionInterval` (available in the [CRAN repository](https://cran.r-project.org/web/packages/predictionInterval/predictionInterval.pdf)), and are reported in @tbl-pis below. In experiment 2, while the estimates of the non-word condition and the FAE fall within the relative prediction interval (*MOP_NW* = -4 ms, *PI_95%* = [-5 1]; *FAE* = 9 ms, *PI_95%* = [6 14]), the estimates of both word conditions are respectively 5 and 4 ms above the corresponding PIs (*MOP_HF* = 26 ms, *PI_95%* = [15 21]; *MOP_LF* = 35 ms, *PI_95%* = [25 31]). Our interpretation of these results is three-fold. First, the fact that the the word priming effects of experiment 2 (for both the high and low-frequency conditions) are outside the prediction intervals of experiment 1 suggest that the effects elicited in experiment 2 may not be considered as mere replications of the effects elicited in experiment 1. Rather, they corroborate the view that priming may significantly benefit from a longer prime duration. Second, the masked repetition non-word priming effect size being replicated in both experiments further corroborates the commonly-accepted view that the masked priming response taps into lexical memory, rather than pure orthographic decoding. Finally, and more importantly for the main purpose of the paper, the estimate of the FAE of experiment falling within the relative prediction interval further confirms the presence of an interaction effect between priming and frequency, while not being contingent on the duration of the prime.\n\n\n\n::: {#tbl-pis .cell tbl-cap='Prediction intervals calculated on the means and standard deviations (SD) of the conditions tested in experiment 1.' tbl-pos='h'}\n\n```{.r .cell-code .hidden}\nlibrary(predictionInterval)\n\nexp1_high <- pi.m(M = exp1_summary.results$MOP[1], SD = exp1_summary.results$sd[1], n = as.numeric(exp1_summary.results$df[1]) + 1, rep.n = as.numeric(exp2_summary.results$df[1]) + 1)\nexp1_low <- pi.m(M = exp1_summary.results$MOP[2], SD = exp1_summary.results$sd[2], n = as.numeric(exp1_summary.results$df[2]) + 1, rep.n = as.numeric(exp2_summary.results$df[2]) + 1)\nexp1_nw <- pi.m(M = exp1_summary.results$MOP[3], SD = exp1_summary.results$sd[3], n = as.numeric(exp1_summary.results$df[3]) + 1, rep.n = as.numeric(exp2_summary.results$df[3]) + 1)\nexp1_fae <- pi.m(M = exp1_summary.results$MOP[4], SD = exp1_summary.results$sd[4], n = as.numeric(exp1_summary.results$df[4]) + 1, rep.n = as.numeric(exp2_summary.results$df[4]) + 1)\n\npis <- data.frame(\n         factor = c(exp1_info$freq_conditions, \"frequency:primetype\"),\n         M = c(exp1_summary.results$MOP[1], exp1_summary.results$MOP[2], exp1_summary.results$MOP[3], exp1_summary.results$MOP[4]),\n         SD = c(exp1_summary.results$sd[1], exp1_summary.results$sd[2], exp1_summary.results$sd[3], exp1_summary.results$sd[4]),\n         N = rep(c(as.numeric(exp1_summary.results$df[1]) + 1), 4),\n         rep.n = rep(c(as.numeric(exp2_summary.results$df[1]) + 1), 4),\n         pi.lb = c(exp1_high$lower_prediction_interval, \n                   exp1_low$lower_prediction_interval, \n                   exp1_nw$lower_prediction_interval,\n                   exp1_fae$lower_prediction_interval),\n         pi.ub = c(exp1_high$upper_prediction_interval, \n                   exp1_low$upper_prediction_interval, \n                   exp1_nw$upper_prediction_interval,\n                   exp1_fae$upper_prediction_interval)\n        )\n\npis %>% \n  mutate(across(c(6:7), round),\n         pi.lb = paste0(\"[\", pi.lb),\n         pi.ub = paste0(pi.ub, \"]\")) %>%\n  unite(\"95% PI\", pi.lb:pi.ub, sep=\" \") %>%\n  gt() %>%\n  cols_label(\n    M = \"mean\",\n    N = \"experiment 1\",\n    rep.n = \"experiment 2\") %>%\n  tab_spanner(\n    label = \"sample size\",\n    columns = c(4:5)\n  )\n```\n\n::: {.cell-output-display}\n\\begin{longtable}{lrrrrl}\n\\toprule\n &  &  & \\multicolumn{2}{c}{sample size} &  \\\\ \n\\cmidrule(lr){4-5}\nfactor & mean & SD & experiment 1 & experiment 2 & 95\\% PI \\\\ \n\\midrule\\addlinespace[2.5pt]\nhigh & 18 & 45 & 2341 & 1924 & [15 21] \\\\ \nlow & 28 & 49 & 2341 & 1924 & [25 31] \\\\ \nnon-word & -2 & 43 & 2341 & 1924 & [-5 1] \\\\ \nfrequency:primetype & 10 & 66 & 2341 & 1924 & [6 14] \\\\ \n\\bottomrule\n\\end{longtable}\n\n:::\n:::\n\n::: {.cell .hidden}\n\n```{.r .cell-code .hidden}\npooled_std <- function(sd1, sd2, n1, n2) {\n  dfs = n1+n2-2\n  term1 = sd1^2*(n1-1)\n  term2 = sd2^2*(n2-1)\n  \n  sp = sqrt((term1+term2)/dfs)\n  return(sp)\n}\n\nd_value <- function(m1, m2, sd1, sd2, n1, n2){\n  sp = pooled_std(sd1, sd2, n1, n2)\n  d = (m1-m2)/sp\n  return(d)\n}\n\nexp1_high_d <- d_value(exp1_summary.results$gd.mean_unrelated[1],\n                       exp1_summary.results$gd.mean_related[1],\n                       exp1_summary.results$sd_unrelated[1],\n                       exp1_summary.results$sd_related[1], \n                       as.numeric(exp1_summary.results$df[1])+1, \n                       as.numeric(exp1_summary.results$df[1])+1)\n\nexp1_low_d <- d_value(exp1_summary.results$gd.mean_unrelated[2],\n                       exp1_summary.results$gd.mean_related[2],\n                       exp1_summary.results$sd_unrelated[2],\n                       exp1_summary.results$sd_related[2], \n                       as.numeric(exp1_summary.results$df[2])+1, \n                       as.numeric(exp1_summary.results$df[2])+1)\n\nexp1_nw_d <- d_value(exp1_summary.results$gd.mean_unrelated[3],\n                       exp1_summary.results$gd.mean_related[3],\n                       exp1_summary.results$sd_unrelated[3],\n                       exp1_summary.results$sd_related[3], \n                       as.numeric(exp1_summary.results$df[3])+1, \n                       as.numeric(exp1_summary.results$df[3])+1)\n\nexp1_d_high <- pi.d(d=exp1_high_d, \n                    n1=as.numeric(exp1_summary.results$df[1])+1,\n                    n2=as.numeric(exp1_summary.results$df[1])+1, \n                    rep.n1 = as.numeric(exp2_summary.results$df[1])+1,\n                    rep.n2 =as.numeric(exp2_summary.results$df[1])+1)\n\nexp1_d_low <- pi.d(d=exp1_low_d, \n                    n1=as.numeric(exp1_summary.results$df[2])+1,\n                    n2=as.numeric(exp1_summary.results$df[2])+1, \n                    rep.n1 = as.numeric(exp2_summary.results$df[2])+1,\n                    rep.n2 =as.numeric(exp2_summary.results$df[2])+1)\n\nexp1_d_nw <- pi.d(d=exp1_nw_d, \n                    n1=as.numeric(exp1_summary.results$df[3])+1,\n                    n2=as.numeric(exp1_summary.results$df[3])+1, \n                    rep.n1 = as.numeric(exp2_summary.results$df[3])+1,\n                    rep.n2 =as.numeric(exp2_summary.results$df[3])+1)\n\npis_d <- data.frame(\n          factor = exp1_info$freq_conditions,\n          d = c(exp1_high_d, exp1_low_d, exp1_nw_d),\n          N = rep(c(as.numeric(exp1_summary.results$df[1]) + 1), 3),\n          rep.n = rep(c(as.numeric(exp2_summary.results$df[1]) + 1), 3),\n          pi.lb = c(exp1_d_high$lower_prediction_interval, \n                   exp1_d_low$lower_prediction_interval, \n                   exp1_d_nw$lower_prediction_interval),\n          pi.ub = c(exp1_d_high$upper_prediction_interval, \n                   exp1_d_low$upper_prediction_interval, \n                   exp1_d_nw$upper_prediction_interval)\n          )\n\n# N.B. these PIs were calculated on the d-values that were in turn calculated over pooled variance, whereas Cohen's d is usually calculated over SD. So the comparison of these PIs with the calculated d's in the table of experiment 2 might not be methodologically sound. One option could be to just give the Cohen's d-values calculated in the table of experiment 1, and take it from there.\n```\n:::\n\n\n\n\n\n\n\n# General discussion {#sec-discussion}\n\n\n\nThe repetition priming response stands as a cornerstone in psycholinguistic investigations, offering insights into the mechanisms governing word recognition. An ongoing debate surrounds the interpretation of these effects, particularly concerning their source in the memory system. On the one hand, _interactive activation models_ [@McClellandRumelhart1981; @GraingerJacobs1996; @ColtheartEtal2001] posit a lexical source for repetition priming effects, either in terms of temporarily raised resting activation levels for lexical nodes in unmasked priming, or as a head start in the retrieval process in masked priming. _Episodic_ and _memory recruitment models_ [@Jacoby1981; @Jacoby1983;  @BodnerMasson1997; @MassonBodner2003; @Bodner2014] on the other hand, invoke a non-lexical source for the repetition effect, namely an episodic or episodic-like memory resource formed upon brief exposure to the prime word that can be recruited during the processing of the target item. Crucially, both models predict a single mechanism underlying masked and unmasked priming. Differential mechanisms between unmasked and masked repetition priming, however, are predicted by the _entry-opening model_ [@ForsterDavis1984], which propose both lexical and episodic sources of priming effects.\n\nThus, the existence of qualitatively distinct outcomes in masked and unmasked priming presented a direct challenge to some, but not all of these models. One such finding is the *Frequency Attenuation Effect* (FAE), in which higher frequency words exhibit smaller repetition effects compared to lower frequency words. The FAE has been described as observable only in unmasked priming since the work of @ForsterDavis1984, who demonstrated that when the prime word is presented very briefly (SOA $<$ 60 ms), it becomes masked by the target word, and this is hypothesized to prevent the conscious encoding of the prime. Under such conditions, the FAE purportedly disappears. @ForsterDavis1984 argued that this potentially shows that the FAE is subserved by a different type of memory source (perhaps episodic) than the masked repetition priming response. This conclusion, however, is the source of ongoing debates (see @tbl-litReview for review of past findings), which the two experiments reported here were meant to address.\n\nWithin this research landscape, our experiments targeting the frequency sensitivity of the repetition effect under masked conditions contribute methodological and theoretical insights. Methodologically, our results help establish the viability and reliability of online data collection for the masked priming paradigm, building on the work of @Angele2023, @Cayado2023 and @PetrosinoEtal2023.\n\nIn the same vein, the FAEs observed in experiments 1 and 2 have important theoretical ramifications. The historical belief that FAE fails to obtain in masked priming arose from a lack of statistically significant results. These were possibly rooted in the reliance of outdated frequency corpora by earlier experiments or inadequate statistical power to detect plausible effect sizes. Our design addressed these concerns, yielding statistically significant FAE results aligning with the literature's average effect (see @tbl-litReview; the 95% CI implies that the FAE is unlikely to be larger than 13 ms with a 33 ms prime duration). These results challenge the supposed qualitative distinction between masked and unmasked repetition priming cleaved by the FAE, complicating the rejection of single-mechanism theories, and suggesting that _interactive-activation models_ and _memory recruitment models_ may yet offer unifying explanations for masked and unmasked priming.\n\nSimilarly, our results also challenge the entry-opening model's prediction of the absence of FAE in masked priming. One potential way of dealing with this in the _entry opening model_ is to claim that masked priming severely reduces, but does not entirely eliminate, the use of sources other than lexical memory [see @Forster1998; @ForsterEtal2003, for proposals along this line]. Alternatively, within the entry-opening model, the results of this study may be explained by the frequency-based mechanism occurring in the fast search stage. A potential mechanism in this direction was already hinted at by @ForsterDavis1984 themselves, and consists of a procedure, whereby during the fast search stage, the entry of a prime word is promoted to the top position of the search list. As a consequence, low-frequency words (which are fairly low in the search list) will benefit from such promotion procedure more than high-frequency words (which are instead already in higher positions), thus ultimately giving rise to the FAE.\n\nWhile our findings present a compelling case for the presence of FAE in masked priming that is seemingly parallel to the unmasked case, questions about potential mechanistic differences persist. The larger sample size needed for masked FAEs raises intriguing considerations about the influence of memory sources and warrants further investigation. For example, there is independent evidence for different mechanisms in masked and unmasked repetition priming from RT distributional analyses (cf. @Gomez2013) that suggests that repetition priming under masked conditions affect primarily the encoding stage of the stimulus. Given that frequency is often associated with facilitation of encoding, our results could help support this view. Additionally, the trivially small inhibitory effect sizes of non-word masked repetition priming in experiments 1 and 2 align with the trend (overwhelmingly shown in the literature) that facilitatory effect may be exclusive to unmasked designs [@Forster1998; @ForsterEtal2003; but see @MassonBodner2003], and suggests avenues for future exploration.\n\nFinally, the finding that the FAE occurs under masked priming conditions may impact our understanding of masked morphological priming. In this literature, there is a unresolved question about the ability of affixes to elicit masked morphological priming results [for a review, @AmentaCrepaldi2012]. In English, the evidence seems to indicate that only stems, but not affixes, have the ability to prime entries across the lexicon. This finding can and has been used to support models in which affixes are initially stripped before stems are accessed in the lexicon [@TaftForster1975; @ForsterAzuma2000; @StockallMarantz2006]. However, stems and affixes do also have a large frequency imbalance, with most affixes being substantially more frequent that most stems. The observation of FAE under masked priming can provide an alternative reason for why masked stem morphological priming is well attested but masked affix morphological priming is not: the latter could be due to a ceiling frequency attenuation effect. This is an intriguing possibility that must be left for future work to explore.\n\nIn summary, our study successfully replicated and expanded upon the work of @Angele2023, @Cayado2023 and @PetrosinoEtal2023, confirming the viability of observing repetition priming effects in masked priming experiments conducted online with a brief SOA of 33 ms. Notably, we addressed a lingering question in the literature by establishing the presence of the Frequency Attenuation Effect (FAE) under masked conditions. The use of large online samples proved instrumental in overcoming the longstanding challenge of insufficient statistical power to detect interactions in factorial designs, which we believe had impeded previous investigations into detecting the FAE in masked priming.\n\n\n\n\n{{< pagebreak >}}\n\n\n\n\n\n\n# References {.unnumbered}\n\n\n\n::: {#refs}\n:::\n\n\n\n{{< pagebreak >}}\n\n\n\n\n\n# Wordlists {.unnumbered}\n\n## Experiment 1 {.unnumbered}\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nexp.wordlist <- read.csv(\"./materials/experiments-1-2/frequency-effects_experiments-1-2_word-lists_final.csv\")\n\nexp1_trial.means <- exp1_data_final %>%\n  group_by(condition_rec, primetype_rec, target_rec, prime_rec) %>%\n  summarise(meanRT = round(mean(RT)), sdRT = round(sd(RT))) %>%\n  pivot_wider(id_cols=target_rec, names_from=primetype_rec, values_from = c(meanRT, sdRT)) %>%\n  ungroup() %>% mutate(target = tolower(target_rec)) %>% select(-target_rec) %>%\n  relocate(target, .before=meanRT_unrelated) %>%\n  relocate(sdRT_unrelated, .after=meanRT_unrelated)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n`summarise()` has grouped output by 'condition_rec', 'primetype_rec',\n'target_rec'. You can override using the `.groups` argument.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nexp.wordlist %>% \n  left_join(., exp1_trial.means, by=join_by(word == target)) %>%\n  mutate(condition = ifelse(condition==\"low\", md(\"*low frequency condition*\"), \n                            ifelse(condition=='high', md(\"*high frequency condition*\"), \"non-word\"))) %>%\n  gt(groupname_col = \"condition\", process_md=T) %>%\n  tab_spanner(\n    label = \"RT (to unrelated)\",\n    columns = contains(\"RT_unrelated\")\n  ) %>%\n  tab_spanner(\n    label = \"RT (to repetition)\",\n    columns = contains(\"RT_related\")\n  ) %>%\n  cols_label(\n    unrelated = \"unrelated prime\",\n    contains(\"mean\") ~ \"mean\",\n    contains(\"sd\") ~ \"SD\"\n  ) %>%\n  sub_missing(\n    missing_text = \"--\"\n  )\n```\n\n::: {.cell-output-display}\n\\begin{longtable}{lllrrrr}\n\\toprule\n &  &  & \\multicolumn{2}{c}{RT (to repetition)} & \\multicolumn{2}{c}{RT (to unrelated)} \\\\ \n\\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\nrelated & unrelated prime & word & mean & SD & mean & SD \\\\ \n\\midrule\\addlinespace[2.5pt]\n\\multicolumn{7}{l}{\\emph{low frequency condition}} \\\\ \n\\midrule\\addlinespace[2.5pt]\narrow & hunch & arrow & 590 & 130 & 587 & 124 \\\\ \npitch & sneak & pitch & 576 & 126 & 612 & 122 \\\\ \nhatch & widow & hatch & 621 & 151 & 639 & 148 \\\\ \nshark & brief & shark & 573 & 125 & 590 & 138 \\\\ \ntooth & sharp & tooth & 536 & 125 & 565 & 116 \\\\ \nbooth & grief & booth & 572 & 136 & 627 & 157 \\\\ \npound & sting & pound & 551 & 127 & 572 & 127 \\\\ \nweigh & thief & weigh & 593 & 167 & 636 & 164 \\\\ \nblank & avoid & blank & 571 & 139 & 596 & 124 \\\\ \ncrush & award & crush & 554 & 128 & 592 & 136 \\\\ \nbench & smack & bench & 573 & 132 & 601 & 129 \\\\ \nfetch & brand & fetch & 622 & 156 & 658 & 146 \\\\ \ncheek & salad & cheek & 561 & 141 & 602 & 142 \\\\ \nbrush & swamp & brush & 564 & 130 & 600 & 128 \\\\ \nmarch & depth & march & 559 & 125 & 580 & 123 \\\\ \nbleed & flesh & bleed & 560 & 148 & 577 & 146 \\\\ \ncliff & harsh & cliff & 602 & 130 & 645 & 137 \\\\ \nfraud & creep & fraud & 621 & 147 & 628 & 132 \\\\ \ncloud & plead & cloud & 536 & 115 & 551 & 101 \\\\ \nfluid & thumb & fluid & 605 & 140 & 678 & 162 \\\\ \ntrash & creek & trash & 554 & 127 & 560 & 128 \\\\ \nflush & blond & flush & 576 & 123 & 617 & 140 \\\\ \nporch & stink & porch & 587 & 136 & 620 & 160 \\\\ \nstiff & patch & stiff & 626 & 154 & 678 & 156 \\\\ \ncough & sweep & cough & 564 & 142 & 601 & 141 \\\\ \nsmash & squad & smash & 570 & 129 & 587 & 126 \\\\ \n\\midrule\\addlinespace[2.5pt]\n\\multicolumn{7}{l}{\\emph{high frequency condition}} \\\\ \n\\midrule\\addlinespace[2.5pt]\nblood & chief & blood & 541 & 130 & 551 & 104 \\\\ \nbunch & child & bunch & 585 & 148 & 617 & 145 \\\\ \ncatch & board & catch & 545 & 116 & 562 & 130 \\\\ \nstuff & tough & stuff & 555 & 119 & 585 & 137 \\\\ \nbreak & stand & break & 545 & 107 & 561 & 124 \\\\ \nspeak & beach & speak & 545 & 131 & 573 & 129 \\\\ \nstick & hotel & stick & 562 & 128 & 598 & 138 \\\\ \nsleep & angel & sleep & 538 & 113 & 559 & 119 \\\\ \nwrong & truth & wrong & 563 & 143 & 565 & 132 \\\\ \ngrand & quick & grand & 571 & 127 & 582 & 143 \\\\ \nmouth & world & mouth & 543 & 125 & 556 & 119 \\\\ \nknock & extra & knock & 560 & 134 & 631 & 136 \\\\ \nguard & think & guard & 580 & 132 & 590 & 134 \\\\ \nsmall & thing & small & 557 & 130 & 577 & 125 \\\\ \ncheck & round & check & 558 & 135 & 562 & 121 \\\\ \nwatch & proud & watch & 541 & 128 & 546 & 110 \\\\ \ngroup & smell & group & 559 & 127 & 576 & 142 \\\\ \nmonth & earth & month & 555 & 120 & 572 & 123 \\\\ \nsouth & relax & south & 575 & 139 & 611 & 133 \\\\ \nlunch & truck & lunch & 547 & 119 & 557 & 125 \\\\ \nclock & throw & clock & 548 & 132 & 574 & 124 \\\\ \nsound & death & sound & 538 & 127 & 552 & 103 \\\\ \ndrink & north & drink & 559 & 129 & 556 & 122 \\\\ \ntouch & young & touch & 541 & 122 & 573 & 121 \\\\ \nlaugh & weird & laugh & 546 & 119 & 568 & 121 \\\\ \nblack & reach & black & 553 & 131 & 563 & 114 \\\\ \n\\midrule\\addlinespace[2.5pt]\n\\multicolumn{7}{l}{non-word} \\\\ \n\\midrule\\addlinespace[2.5pt]\nalkew & grack & alkew & 599 & 153 & 591 & 140 \\\\ \nagink & furob & agink & 626 & 148 & 614 & 141 \\\\ \nruzak & begro & ruzak & 577 & 130 & 584 & 142 \\\\ \nsondo & labok & sondo & 625 & 142 & 612 & 149 \\\\ \nguesh & gazzo & guesh & 702 & 184 & 721 & 194 \\\\ \nfadio & criam & fadio & 618 & 149 & 604 & 146 \\\\ \nplich & coreb & plich & 650 & 162 & 640 & 159 \\\\ \nsgrew & docab & sgrew & 626 & 182 & 638 & 182 \\\\ \nsceak & colob & sceak & 675 & 154 & 683 & 171 \\\\ \nghisk & isloo & ghisk & 588 & 139 & 593 & 139 \\\\ \ndeirm & ahuck & deirm & 589 & 142 & 596 & 139 \\\\ \nvillo & flurb & villo & 632 & 182 & 615 & 181 \\\\ \ntidow & pikto & tidow & 648 & 167 & 624 & 160 \\\\ \ndrick & aliom & drick & 684 & 168 & 681 & 172 \\\\ \nphick & purso & phick & 643 & 160 & 637 & 165 \\\\ \nnello & borno & nello & 625 & 156 & 612 & 151 \\\\ \nfeach & pacaw & feach & 730 & 201 & 720 & 192 \\\\ \ntello & rilth & tello & 651 & 175 & 644 & 171 \\\\ \ndolio & caveb & dolio & 602 & 148 & 610 & 165 \\\\ \ngorgo & swysh & gorgo & 643 & 164 & 619 & 170 \\\\ \nwhilo & lanjo & whilo & 612 & 137 & 604 & 150 \\\\ \nstanf & drief & stanf & 611 & 134 & 617 & 133 \\\\ \ncrulk & ocheb & crulk & 671 & 162 & 665 & 169 \\\\ \nphumb & tunch & phumb & 645 & 160 & 633 & 148 \\\\ \nsirth & steaf & sirth & 612 & 141 & 618 & 145 \\\\ \nslerk & nohew & slerk & 640 & 153 & 634 & 163 \\\\ \nvitbo & nualm & vitbo & 593 & 151 & 596 & 154 \\\\ \nsunch & ofium & sunch & 665 & 165 & 665 & 161 \\\\ \nsoeth & croik & soeth & 589 & 141 & 589 & 130 \\\\ \neltow & valuo & eltow & 628 & 171 & 606 & 158 \\\\ \nframo & sorgo & framo & 617 & 146 & 618 & 146 \\\\ \nlumpo & shavo & lumpo & 630 & 162 & 635 & 172 \\\\ \nspuff & oceab & spuff & 672 & 169 & 667 & 183 \\\\ \ngatob & tolio & gatob & 599 & 139 & 606 & 155 \\\\ \nnosom & theck & nosom & 598 & 155 & 604 & 139 \\\\ \ngezzo & tooch & gezzo & 592 & 136 & 586 & 131 \\\\ \nafoub & slonk & afoub & 582 & 133 & 589 & 128 \\\\ \nwateb & salch & wateb & 633 & 151 & 619 & 133 \\\\ \nnelch & raceb & nelch & 601 & 144 & 594 & 145 \\\\ \ndahoo & ahack & dahoo & 598 & 132 & 595 & 146 \\\\ \ndriek & fideo & driek & 606 & 145 & 606 & 143 \\\\ \ngnask & fluko & gnask & 612 & 171 & 604 & 153 \\\\ \nbrosk & cyrrh & brosk & 629 & 159 & 647 & 175 \\\\ \nduvez & revuo & duvez & 580 & 152 & 580 & 155 \\\\ \nfielm & cempo & fielm & 609 & 146 & 611 & 151 \\\\ \npumph & exulk & pumph & 669 & 162 & 685 & 176 \\\\ \ngerif & kleck & gerif & 584 & 137 & 588 & 149 \\\\ \nracef & bonth & racef & 618 & 151 & 622 & 156 \\\\ \npheek & scook & pheek & 640 & 155 & 644 & 176 \\\\ \npruaw & slork & pruaw & 593 & 133 & 592 & 135 \\\\ \nguilm & whilf & guilm & 603 & 142 & 598 & 142 \\\\ \nlairf & drosh & lairf & 587 & 144 & 600 & 150 \\\\ \n\\bottomrule\n\\end{longtable}\n\n:::\n:::\n\n\n\n## Experiment 2 {.unnumbered}\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nexp2_trial.means <- exp2_data_final %>%\n  group_by(condition_rec, primetype_rec, target_rec, prime_rec) %>%\n  summarise(meanRT = round(mean(RT)), sdRT = round(sd(RT))) %>%\n  pivot_wider(id_cols=target_rec, names_from=primetype_rec, values_from = c(meanRT, sdRT)) %>%\n  ungroup() %>% mutate(target = tolower(target_rec)) %>% select(-target_rec) %>%\n  relocate(target, .before=meanRT_unrelated) %>%\n  relocate(sdRT_unrelated, .after=meanRT_unrelated)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n`summarise()` has grouped output by 'condition_rec', 'primetype_rec',\n'target_rec'. You can override using the `.groups` argument.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nexp.wordlist %>% \n  left_join(., exp2_trial.means, by=join_by(word == target)) %>%\n  mutate(condition = ifelse(condition==\"low\", md(\"*low frequency condition*\"), \n                            ifelse(condition=='high', md(\"*high frequency condition*\"), \"non-word\"))) %>%\n  gt(groupname_col = \"condition\", process_md=T) %>%\n  tab_spanner(\n    label = \"RT (to unrelated)\",\n    columns = contains(\"RT_unrelated\")\n  ) %>%\n  tab_spanner(\n    label = \"RT (to repetition)\",\n    columns = contains(\"RT_related\")\n  ) %>%\n  cols_label(\n    unrelated = \"unrelated prime\",\n    contains(\"mean\") ~ \"mean\",\n    contains(\"sd\") ~ \"SD\"\n  ) %>%\n  sub_missing(\n    missing_text = \"--\"\n  )\n```\n\n::: {.cell-output-display}\n\\begin{longtable}{lllrrrr}\n\\toprule\n &  &  & \\multicolumn{2}{c}{RT (to repetition)} & \\multicolumn{2}{c}{RT (to unrelated)} \\\\ \n\\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\nrelated & unrelated prime & word & mean & SD & mean & SD \\\\ \n\\midrule\\addlinespace[2.5pt]\n\\multicolumn{7}{l}{\\emph{low frequency condition}} \\\\ \n\\midrule\\addlinespace[2.5pt]\narrow & hunch & arrow & 573 & 130 & 591 & 128 \\\\ \npitch & sneak & pitch & 565 & 132 & 608 & 146 \\\\ \nhatch & widow & hatch & 606 & 163 & 644 & 164 \\\\ \nshark & brief & shark & 560 & 132 & 587 & 124 \\\\ \ntooth & sharp & tooth & 533 & 126 & 560 & 111 \\\\ \nbooth & grief & booth & 566 & 147 & 618 & 163 \\\\ \npound & sting & pound & 552 & 139 & 570 & 134 \\\\ \nweigh & thief & weigh & 583 & 158 & 649 & 186 \\\\ \nblank & avoid & blank & 556 & 132 & 583 & 132 \\\\ \ncrush & award & crush & 542 & 126 & 583 & 142 \\\\ \nbench & smack & bench & 565 & 143 & 601 & 138 \\\\ \nfetch & brand & fetch & 612 & 149 & 663 & 146 \\\\ \ncheek & salad & cheek & 556 & 138 & 597 & 148 \\\\ \nbrush & swamp & brush & 559 & 136 & 593 & 125 \\\\ \nmarch & depth & march & 560 & 149 & 575 & 122 \\\\ \nbleed & flesh & bleed & 552 & 137 & 568 & 135 \\\\ \ncliff & harsh & cliff & 595 & 149 & 662 & 157 \\\\ \nfraud & creep & fraud & 596 & 131 & 634 & 113 \\\\ \ncloud & plead & cloud & 539 & 132 & 552 & 108 \\\\ \nfluid & thumb & fluid & 601 & 167 & 690 & 173 \\\\ \ntrash & creek & trash & 564 & 157 & 566 & 126 \\\\ \nflush & blond & flush & 570 & 133 & 624 & 155 \\\\ \nporch & stink & porch & 584 & 155 & 617 & 153 \\\\ \nstiff & patch & stiff & 617 & 163 & 677 & 161 \\\\ \ncough & sweep & cough & 552 & 136 & 591 & 145 \\\\ \nsmash & squad & smash & 553 & 133 & 590 & 142 \\\\ \n\\midrule\\addlinespace[2.5pt]\n\\multicolumn{7}{l}{\\emph{high frequency condition}} \\\\ \n\\midrule\\addlinespace[2.5pt]\nblood & chief & blood & 534 & 131 & 558 & 112 \\\\ \nbunch & child & bunch & 584 & 156 & 619 & 146 \\\\ \ncatch & board & catch & 529 & 111 & 568 & 141 \\\\ \nstuff & tough & stuff & 556 & 128 & 576 & 133 \\\\ \nbreak & stand & break & 542 & 128 & 564 & 123 \\\\ \nspeak & beach & speak & 543 & 131 & 570 & 132 \\\\ \nstick & hotel & stick & 556 & 136 & 599 & 130 \\\\ \nsleep & angel & sleep & 525 & 111 & 566 & 137 \\\\ \nwrong & truth & wrong & 555 & 142 & 569 & 137 \\\\ \ngrand & quick & grand & 564 & 129 & 588 & 147 \\\\ \nmouth & world & mouth & 534 & 123 & 552 & 116 \\\\ \nknock & extra & knock & 549 & 131 & 615 & 139 \\\\ \nguard & think & guard & 565 & 118 & 590 & 118 \\\\ \nsmall & thing & small & 549 & 137 & 567 & 130 \\\\ \ncheck & round & check & 546 & 125 & 563 & 120 \\\\ \nwatch & proud & watch & 531 & 115 & 545 & 133 \\\\ \ngroup & smell & group & 553 & 126 & 579 & 142 \\\\ \nmonth & earth & month & 549 & 126 & 576 & 128 \\\\ \nsouth & relax & south & 563 & 138 & 603 & 144 \\\\ \nlunch & truck & lunch & 549 & 141 & 563 & 124 \\\\ \nclock & throw & clock & 547 & 133 & 574 & 130 \\\\ \nsound & death & sound & 534 & 127 & 559 & 147 \\\\ \ndrink & north & drink & 550 & 124 & 563 & 116 \\\\ \ntouch & young & touch & 545 & 145 & 567 & 120 \\\\ \nlaugh & weird & laugh & 535 & 113 & 556 & 114 \\\\ \nblack & reach & black & 547 & 129 & 578 & 129 \\\\ \n\\midrule\\addlinespace[2.5pt]\n\\multicolumn{7}{l}{non-word} \\\\ \n\\midrule\\addlinespace[2.5pt]\nalkew & grack & alkew & 603 & 150 & 606 & 160 \\\\ \nagink & furob & agink & 632 & 161 & 615 & 155 \\\\ \nruzak & begro & ruzak & 580 & 149 & 582 & 155 \\\\ \nsondo & labok & sondo & 619 & 168 & 621 & 178 \\\\ \nguesh & gazzo & guesh & 707 & 189 & 748 & 195 \\\\ \nfadio & criam & fadio & 632 & 169 & 602 & 171 \\\\ \nplich & coreb & plich & 645 & 148 & 646 & 180 \\\\ \nsgrew & docab & sgrew & 637 & 197 & 648 & 184 \\\\ \nsceak & colob & sceak & 692 & 179 & 692 & 165 \\\\ \nghisk & isloo & ghisk & 595 & 149 & 594 & 152 \\\\ \ndeirm & ahuck & deirm & 599 & 147 & 595 & 147 \\\\ \nvillo & flurb & villo & 637 & 210 & 615 & 178 \\\\ \ntidow & pikto & tidow & 651 & 175 & 641 & 177 \\\\ \ndrick & aliom & drick & 696 & 194 & 685 & 186 \\\\ \nphick & purso & phick & 648 & 176 & 639 & 168 \\\\ \nnello & borno & nello & 631 & 178 & 637 & 189 \\\\ \nfeach & pacaw & feach & 748 & 201 & 745 & 208 \\\\ \ntello & rilth & tello & 665 & 185 & 662 & 174 \\\\ \ndolio & caveb & dolio & 618 & 175 & 609 & 157 \\\\ \ngorgo & swysh & gorgo & 651 & 179 & 631 & 178 \\\\ \nwhilo & lanjo & whilo & 619 & 150 & 615 & 164 \\\\ \nstanf & drief & stanf & 613 & 147 & 627 & 134 \\\\ \ncrulk & ocheb & crulk & 678 & 173 & 679 & 183 \\\\ \nphumb & tunch & phumb & 655 & 175 & 648 & 180 \\\\ \nsirth & steaf & sirth & 623 & 146 & 616 & 136 \\\\ \nslerk & nohew & slerk & 644 & 167 & 638 & 172 \\\\ \nvitbo & nualm & vitbo & 590 & 143 & 596 & 154 \\\\ \nsunch & ofium & sunch & 664 & 162 & 676 & 172 \\\\ \nsoeth & croik & soeth & 590 & 131 & 589 & 146 \\\\ \neltow & valuo & eltow & 638 & 170 & 603 & 153 \\\\ \nframo & sorgo & framo & 626 & 165 & 631 & 162 \\\\ \nlumpo & shavo & lumpo & 634 & 172 & 635 & 164 \\\\ \nspuff & oceab & spuff & 683 & 182 & 665 & 204 \\\\ \ngatob & tolio & gatob & 607 & 167 & 594 & 154 \\\\ \nnosom & theck & nosom & 603 & 156 & 608 & 160 \\\\ \ngezzo & tooch & gezzo & 601 & 160 & 600 & 164 \\\\ \nafoub & slonk & afoub & 583 & 136 & 587 & 133 \\\\ \nwateb & salch & wateb & 640 & 159 & 641 & 160 \\\\ \nnelch & raceb & nelch & 609 & 163 & 595 & 145 \\\\ \ndahoo & ahack & dahoo & 611 & 157 & 597 & 154 \\\\ \ndriek & fideo & driek & 613 & 152 & 610 & 151 \\\\ \ngnask & fluko & gnask & 606 & 154 & 606 & 159 \\\\ \nbrosk & cyrrh & brosk & 637 & 165 & 649 & 180 \\\\ \nduvez & revuo & duvez & 590 & 168 & 576 & 154 \\\\ \nfielm & cempo & fielm & 621 & 181 & 614 & 160 \\\\ \npumph & exulk & pumph & 687 & 184 & 697 & 202 \\\\ \ngerif & kleck & gerif & 587 & 154 & 586 & 147 \\\\ \nracef & bonth & racef & 619 & 164 & 621 & 151 \\\\ \npheek & scook & pheek & 641 & 157 & 635 & 169 \\\\ \npruaw & slork & pruaw & 599 & 157 & 598 & 143 \\\\ \nguilm & whilf & guilm & 620 & 168 & 603 & 163 \\\\ \nlairf & drosh & lairf & 590 & 138 & 597 & 146 \\\\ \n\\bottomrule\n\\end{longtable}\n\n:::\n:::\n",
    "supporting": [
      "index_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "\\usepackage{booktabs}\n\\usepackage{caption}\n\\usepackage{longtable}\n\\usepackage{colortbl}\n\\usepackage{array}\n"
      ]
    },
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}